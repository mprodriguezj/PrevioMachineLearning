import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import (
    RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier,
    RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor
)
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import label_binarize

def ensemble_models_module(df):
    st.subheader("Selecci√≥n de Modelos de Ensamble")
    
    # --- INICIALIZACI√ìN DE ESTADO ---
    if 'ensemble_current_state' not in st.session_state:
        st.session_state.ensemble_current_state = {}
    
    # --- DETECCI√ìN DE CAMBIOS ---
    current_config = {
        'target_col': None,
        'selected_features': None,
        'cleaning_strategy': None,
        'numeric_option': None,
        'discretize_method': None,
        'n_bins': None,
        'test_size': None,
        'random_state': None,
        'selected_models': None,
        'rf_params': None,
        'ab_params': None,
        'gb_params': None,
        'bag_params': None
    }
    
    # Informaci√≥n introductoria
    with st.expander("Acerca de los Modelos de Ensamble"):
        st.markdown("""
        Los modelos de ensamble combinan m√∫ltiples algoritmos de aprendizaje
        para lograr un mejor rendimiento predictivo que un √∫nico modelo.

        **Ventajas principales:**
        - Reducen el sobreajuste (overfitting)
        - Mejoran la generalizaci√≥n
        - Son m√°s robustos frente a datos ruidosos
        """)
    
    # Selecci√≥n de modelos
    st.write("**Selecciona los modelos a comparar:**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        rf_selected = st.checkbox("Random Forest", value=True, key="rf_checkbox")
    with col2:
        ab_selected = st.checkbox("AdaBoost", value=True, key="ab_checkbox")
    with col3:
        gb_selected = st.checkbox("Gradient Boosting", value=True, key="gb_checkbox")
    with col4:
        bag_selected = st.checkbox("Bagging", value=True, key="bag_checkbox")
    
    selected_models = []
    if rf_selected:
        selected_models.append("Random Forest")
    if ab_selected:
        selected_models.append("AdaBoost")
    if gb_selected:
        selected_models.append("Gradient Boosting")
    if bag_selected:
        selected_models.append("Bagging")
    
    current_config['selected_models'] = tuple(selected_models)
    
    if not selected_models:
        st.warning("‚ö†Ô∏è Selecciona al menos un modelo para comparar")
        return
    
    # Preparaci√≥n de datos
    st.write("**Preparaci√≥n de datos:**")
    
    col1, col2 = st.columns(2)
    with col1:
        target_col = st.selectbox(
            "Selecciona la variable objetivo:",
            df.columns,
            key="target_select_ensemble"
        )
        current_config['target_col'] = target_col
    
    with col2:
        available_features = [col for col in df.columns if col != target_col]
        selected_features = st.multiselect(
            "Selecciona las variables predictoras:",
            available_features,
            default=available_features,
            key="features_select_ensemble"
        )
        current_config['selected_features'] = tuple(selected_features)
    
    if not selected_features:
        st.warning("‚ö†Ô∏è Selecciona al menos una variable predictora")
        return
    
    # Construir X, y
    X = df[selected_features]
    y = df[target_col]
    
    # --- Limpieza y procesamiento de datos MEJORADO ---
    st.write("**Limpieza y procesamiento de datos:**")

    rows_before = len(X)

    # Verificar si hay valores infinitos o nulos
    has_inf = np.any(np.isinf(X.select_dtypes(include=['float64', 'int64']).values), axis=1).any()
    has_nulls_X = X.isnull().any().any()
    has_nulls_y = y.isnull().any()

    # Solo mostrar opciones de limpieza si hay valores problem√°ticos
    if has_inf or has_nulls_X or has_nulls_y:
        cleaning_strategy = st.selectbox(
            "Estrategia para manejar valores faltantes/infinitos:",
            ["Eliminar filas afectadas", "Rellenar con valores apropiados"],
            help="Eliminar: M√°s conservador | Rellenar: Preserva m√°s datos",
            key="cleaning_strategy_ensemble"
        )
        current_config['cleaning_strategy'] = cleaning_strategy
    else:
        cleaning_strategy = "Eliminar filas afectadas"
        st.info("‚ÑπÔ∏è No se detectaron valores infinitos ni nulos en el dataset")

    # 1. Manejar valores infinitos - solo si existen
    inf_mask = np.any(np.isinf(X.select_dtypes(include=['float64', 'int64']).values), axis=1)
    if inf_mask.any():
        st.warning(f"‚ö†Ô∏è Se detectaron {inf_mask.sum()} filas con valores infinitos.")
        
        if cleaning_strategy == "Eliminar filas afectadas":
            X = X[~inf_mask]
            y = y[~inf_mask]
            st.success("‚úÖ Filas con infinitos ELIMINADAS")
        else:
            # Reemplazar infinitos por NaN para luego imputar
            X = X.replace([np.inf, -np.inf], np.nan)
            st.info("‚ÑπÔ∏è Infinitos convertidos a NaN para imputaci√≥n")

    # 2. Manejar valores nulos - solo si existen
    total_missing_X = X.isnull().any(axis=1).sum()
    total_missing_y = y.isnull().sum()

    # Solo mostrar resumen si hay nulos
    if total_missing_X > 0 or total_missing_y > 0:
        st.write(f"**Resumen de valores nulos:**")
        if total_missing_X > 0:
            st.write(f"- Filas con nulos en predictores (X): {total_missing_X}")
        if total_missing_y > 0:
            st.write(f"- Filas con nulos en objetivo (y): {total_missing_y}")

    # Estrategia diferente para X vs y - solo aplicar si hay nulos
    if has_nulls_X or has_nulls_y:
        if cleaning_strategy == "Eliminar filas afectadas":
            # ELIMINAR: M√°s seguro para el modelo
            missing_mask = X.isnull().any(axis=1) | y.isnull()
            if missing_mask.any():
                rows_removed = missing_mask.sum()
                X = X[~missing_mask]
                y = y[~missing_mask]
                st.success(f"‚úÖ Se eliminaron {rows_removed} filas con valores nulos")
                
        else:
            # RELLENAR: Preserva datos
            # Para X: Imputar por tipo de variable
            numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            
            # Rellenar num√©ricos con mediana (m√°s robusta que media)
            for col in numeric_cols:
                if X[col].isna().any():
                    X[col] = X[col].fillna(X[col].median())
                    st.info(f"‚ÑπÔ∏è Num√©rico '{col}': nulos rellenados con mediana ({X[col].median():.2f})")
            
            # Rellenar categ√≥ricos con moda
            for col in categorical_cols:
                if X[col].isna().any():
                    mode_val = X[col].mode()[0] if not X[col].mode().empty else "DESCONOCIDO"
                    X[col] = X[col].fillna(mode_val)
                    st.info(f"‚ÑπÔ∏è Categ√≥rico '{col}': nulos rellenados con moda ('{mode_val}')")
            
            # Para y: Solo eliminar (cr√≠tico para el objetivo)
            if y.isnull().any():
                y_null_count = y.isnull().sum()
                mask = ~y.isnull()
                X = X[mask]
                y = y[mask]
                st.success(f"‚úÖ Se eliminaron {y_null_count} filas con nulos en variable objetivo (CR√çTICO)")

    # 3. Verificaci√≥n final - solo mostrar si hubo cambios
    rows_after = len(X)
    rows_removed_total = rows_before - rows_after

    if rows_removed_total > 0:
        removal_percentage = (rows_removed_total / rows_before) * 100
        st.warning(f"‚ö†Ô∏è Resumen final: {rows_removed_total} filas removidas ({removal_percentage:.1f}%)")
        
        if removal_percentage > 30:
            st.error("‚ùå ¬°Alto porcentaje de datos perdidos! Considera revisar tu dataset")
        elif removal_percentage > 10:
            st.warning("‚ö†Ô∏è Porcentaje moderado de datos perdidos")
    else:
        st.info("‚ÑπÔ∏è No se removieron filas durante la limpieza")

    st.info(f"‚ÑπÔ∏è Filas restantes para modelo: {rows_after}")

    if len(X) < 10:
        st.error("‚ùå Dataset demasiado peque√±o despu√©s de limpieza. No se puede continuar.")
        return
    elif len(X) < 50:
        st.warning("‚ö†Ô∏è Dataset muy peque√±o. Los resultados pueden no ser confiables.")
        
    # Detectar variables categ√≥ricas (solo expl√≠citas - objetos y categor√≠as)
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    if categorical_cols:
        st.info(f"‚ÑπÔ∏è Variables categ√≥ricas detectadas: {', '.join(categorical_cols)}")
        
        # Convertir a dummies con manejo de errores m√°s robusto
        try:
            # Crear una copia de seguridad de X
            X_backup = X.copy()
            
            # Convertir solo las columnas categ√≥ricas
            X_cat = pd.get_dummies(X[categorical_cols], drop_first=True, dummy_na=False)
            
            # Mantener las columnas num√©ricas que no son categ√≥ricas
            non_cat_cols = [col for col in X.columns if col not in categorical_cols]
            X_non_cat = X[non_cat_cols]
            
            # Combinar ambos conjuntos de datos
            X = pd.concat([X_non_cat, X_cat], axis=1)
            
            st.success(f"‚úÖ Variables categ√≥ricas convertidas a one-hot encoding. Nuevas dimensiones: {X.shape}")
        except Exception as e:
            st.error(f"‚ùå Error al convertir variables categ√≥ricas: {str(e)}")
            st.warning("Intentando m√©todo alternativo de conversi√≥n...")
            
            try:
                # Restaurar X desde la copia de seguridad
                X = X_backup.copy()
                
                # M√©todo alternativo: convertir una por una
                for col in categorical_cols:
                    try:
                        # Convertir a string primero para manejar diferentes tipos de datos
                        X[col] = X[col].astype(str)
                    except Exception as e_col:
                        st.warning(f"No se pudo convertir la columna '{col}': {str(e_col)}")
                
                # Intentar la conversi√≥n con manejo expl√≠cito de columnas
                dummies_list = []
                remaining_cols = []
                
                for col in X.columns:
                    if col in categorical_cols:
                        try:
                            # Crear dummies para esta columna
                            dummies = pd.get_dummies(X[col], prefix=col, drop_first=True)
                            dummies_list.append(dummies)
                        except Exception as e_dummy:
                            st.warning(f"Error al crear dummies para '{col}': {str(e_dummy)}")
                            # Mantener la columna original si falla
                            remaining_cols.append(col)
                    else:
                        remaining_cols.append(col)
                
                # Reconstruir el DataFrame
                if dummies_list:
                    all_dummies = pd.concat(dummies_list, axis=1)
                    X = pd.concat([X[remaining_cols], all_dummies], axis=1)
                    st.success(f"‚úÖ Variables convertidas con m√©todo alternativo. Nuevas dimensiones: {X.shape}")
                else:
                    st.warning("‚ö†Ô∏è No se pudieron crear variables dummy. Manteniendo variables originales.")
            except Exception as e2:
                st.error(f"‚ùå Error en m√©todo alternativo: {str(e2)}")
                st.warning("‚ö†Ô∏è Continuando con las variables originales sin convertir a dummies.")
    else:
        st.info("‚ÑπÔ∏è No se detectaron variables categ√≥ricas en los predictores")
        st.info("‚úÖ **One-hot encoding:** No requerido - no hay variables categ√≥ricas")
    
    # Procesamiento de variable objetivo
    # Detectar si la variable objetivo es num√©rica o categ√≥rica
    is_numeric_target = pd.api.types.is_numeric_dtype(y)
    
    # Variable para controlar si usamos regresi√≥n o clasificaci√≥n
    use_regression_model = True  # Valor por defecto
    
    if is_numeric_target:
        st.info(f"‚ÑπÔ∏è Variable objetivo '{target_col}' detectada como num√©rica/continua")
        
        # Para variables num√©ricas, verificamos valores nulos y outliers
        if y.isna().any():
            st.warning(f"‚ö†Ô∏è Se eliminaron {y.isna().sum()} filas con valores nulos en la variable objetivo")
            mask = ~y.isna()
            X = X[mask]
            y = y[mask]
        
        # Detectar y manejar outliers (opcional)
        Q1 = y.quantile(0.25)
        Q3 = y.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = (y < lower_bound) | (y > upper_bound)
        
        if outliers.sum() > 0:
            st.info(f"‚ÑπÔ∏è Se detectaron {outliers.sum()} valores at√≠picos en la variable objetivo")
        
        # Opciones para manejar variables num√©ricas
        st.subheader("Opciones para variable objetivo num√©rica")
        numeric_option = st.radio(
            "¬øC√≥mo deseas manejar la variable objetivo num√©rica?",
            ["Discretizar en intervalos para clasificaci√≥n", "Usar modelo de regresi√≥n"],
            key="numeric_option_ensemble"
        )
        current_config['numeric_option'] = numeric_option
        
        if numeric_option == "Discretizar en intervalos para clasificaci√≥n":
            use_regression_model = False
            # Opciones de discretizaci√≥n
            discretize_method = st.selectbox(
                "M√©todo de discretizaci√≥n:",
                ["Intervalos iguales", "Cuantiles", "Personalizado"],
                key="discretize_method_ensemble"
            )
            current_config['discretize_method'] = discretize_method
            
            if discretize_method == "Intervalos iguales":
                n_bins = st.slider("N√∫mero de intervalos:", 2, 10, 4, key="n_bins_equal_ensemble")
                current_config['n_bins'] = n_bins
                # Discretizar en intervalos iguales
                bins = np.linspace(y.min(), y.max(), n_bins + 1)
                labels = [f'{bins[i]:.2f}-{bins[i+1]:.2f}' for i in range(len(bins)-1)]
                y_discretized = pd.cut(y, bins=bins, labels=labels, include_lowest=True)
                
                # Mostrar distribuci√≥n de clases
                class_counts = y_discretized.value_counts().sort_index()
                st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                st.bar_chart(class_counts)
                
                # Reemplazar la variable objetivo con la versi√≥n discretizada
                y = y_discretized
                st.success(f"‚úÖ Variable objetivo discretizada en {n_bins} intervalos iguales")
                is_numeric_target = False
                
            elif discretize_method == "Cuantiles":
                n_bins = st.slider("N√∫mero de cuantiles:", 2, 10, 4, key="n_bins_quantile_ensemble")
                current_config['n_bins'] = n_bins
                # Discretizar por cuantiles
                bins = pd.qcut(y, q=n_bins, retbins=True)[1]
                labels = [f'{bins[i]:.2f}-{bins[i+1]:.2f}' for i in range(len(bins)-1)]
                y_discretized = pd.cut(y, bins=bins, labels=labels, include_lowest=True)
                
                # Mostrar distribuci√≥n de clases
                class_counts = y_discretized.value_counts().sort_index()
                st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                st.bar_chart(class_counts)
                
                # Reemplazar la variable objetivo con la versi√≥n discretizada
                y = y_discretized
                st.success(f"‚úÖ Variable objetivo discretizada en {n_bins} cuantiles")
                is_numeric_target = False
                
            elif discretize_method == "Personalizado":
                use_regression_model = False
                # Permitir al usuario definir puntos de corte personalizados
                min_val = float(y.min())
                max_val = float(y.max())
                
                st.write(f"Rango de valores: {min_val:.2f} a {max_val:.2f}")
                
                # Entrada de texto para puntos de corte
                cutpoints_text = st.text_input(
                    "Puntos de corte (separados por coma):",
                    value=f"{min_val},{(min_val+max_val)/2:.2f},{max_val}",
                    key="custom_cutpoints_ensemble"
                )
                
                try:
                    # Convertir texto a lista de puntos de corte
                    cutpoints = [float(x.strip()) for x in cutpoints_text.split(",")]
                    cutpoints = sorted(list(set(cutpoints)))  # Eliminar duplicados y ordenar
                    
                    if len(cutpoints) < 2:
                        st.error("‚ùå Se necesitan al menos 2 puntos de corte")
                    else:
                        # Asegurarse de que los puntos de corte cubran todo el rango
                        if cutpoints[0] > min_val:
                            cutpoints.insert(0, min_val)
                        if cutpoints[-1] < max_val:
                            cutpoints.append(max_val)
                        
                        # Crear etiquetas y discretizar
                        labels = [f'{cutpoints[i]:.2f}-{cutpoints[i+1]:.2f}' for i in range(len(cutpoints)-1)]
                        y_discretized = pd.cut(y, bins=cutpoints, labels=labels, include_lowest=True)
                        
                        # Mostrar distribuci√≥n de clases
                        class_counts = y_discretized.value_counts().sort_index()
                        st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                        st.bar_chart(class_counts)
                        
                        # Reemplazar la variable objetivo con la versi√≥n discretizada
                        y = y_discretized
                        st.success(f"‚úÖ Variable objetivo discretizada con puntos de corte personalizados")
                        is_numeric_target = False
                        
                except Exception as e:
                    st.error(f"‚ùå Error al procesar puntos de corte: {str(e)}")
        else:
            # Para √°rboles de decisi√≥n con variable objetivo num√©rica, usamos DecisionTreeRegressor
            use_regression_model = True
            st.info("‚ÑπÔ∏è Se utilizar√° un modelo de regresi√≥n para la variable objetivo num√©rica")
        
    else:
        st.info(f"‚ÑπÔ∏è Variable objetivo '{target_col}' detectada como categ√≥rica")
        use_regression_model = False
        
        # Para variables categ√≥ricas, limpiamos y procesamos
        y = y.astype(str).str.strip()
        y = y.replace("?", np.nan)
        mask = ~y.isna()
        X = X[mask]
        y = y[mask]

        # Eliminaci√≥n de clases raras
        class_counts = y.value_counts()
        rare_classes = class_counts[class_counts < 2].index
        if len(rare_classes) > 0:
            st.warning(f"‚ö†Ô∏è Se eliminaron {len(rare_classes)} clases con menos de 2 muestras")
            mask = ~y.isin(rare_classes)
            X = X[mask]
            y = y[mask]
        
        # Validaci√≥n final para clasificaci√≥n
        if len(y.unique()) < 2:
            st.error("‚ùåNo hay suficientes clases para entrenar el modelo. Se necesitan al menos 2 clases diferentes.")
            return
    
    # --- Configuraci√≥n de divisi√≥n de datos ---
    st.write("**Configuraci√≥n de divisi√≥n de datos:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        test_size = st.slider("Tama√±o del conjunto de prueba:", 0.1, 0.4, 0.2, 0.05,
                            key="test_size_ensemble")
        current_config['test_size'] = test_size
    
    with col2:
        random_state = st.number_input("Random state:", 0, 100, 42, key="random_state_ensemble")
        current_config['random_state'] = random_state
    
    # Validar estratificaci√≥n
    can_stratify = len(y.unique()) >= 2 and y.value_counts().min() >= 2
    
    # Divisi√≥n del dataset
    try:
        if can_stratify and not use_regression_model:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=test_size,
                random_state=random_state,
                stratify=y,
                shuffle=True
            )
            st.success("‚úÖ Divisi√≥n estratificada realizada correctamente")
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=test_size,
                random_state=random_state,
                shuffle=True
            )
            st.info("‚ÑπÔ∏è Divisi√≥n no estratificada realizada")
    except ValueError as e:
        st.warning(f"‚ö†Ô∏è Divisi√≥n estratificada fall√≥: {e}. Reintentando sin estratificaci√≥n...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=test_size,
            random_state=random_state,
            shuffle=True
        )
    
    # --- Configuraci√≥n de modelos con explicaciones ---
    models_config = {}
    
    if "Random Forest" in selected_models:
        st.subheader("Random Forest")
        with st.expander("Explicaci√≥n de Random Forest"):
            if use_regression_model:
                st.markdown("""
                **Random Forest para Regresi√≥n** combina m√∫ltiples √°rboles de regresi√≥n.
                
                **C√≥mo funciona:**
                1. Crea m√∫ltiples √°rboles de regresi√≥n con subconjuntos aleatorios de datos
                2. En cada divisi√≥n del √°rbol, considera solo un subconjunto aleatorio de caracter√≠sticas
                3. Combina las predicciones de todos los √°rboles (promedio para regresi√≥n)
                
                **Ventajas:**
                - Alta precisi√≥n en problemas de regresi√≥n
                - Resistente al sobreajuste
                - Maneja bien datos con muchas caracter√≠sticas
                """)
            else:
                st.markdown("""
                **Random Forest** es un algoritmo de ensamble que combina m√∫ltiples √°rboles de decisi√≥n.
                
                **C√≥mo funciona:**
                1. Crea m√∫ltiples √°rboles de decisi√≥n con subconjuntos aleatorios de datos (bootstrapping)
                2. En cada divisi√≥n del √°rbol, considera solo un subconjunto aleatorio de caracter√≠sticas
                3. Combina las predicciones de todos los √°rboles (votaci√≥n mayoritaria para clasificaci√≥n)
                
                **Ventajas:**
                - Alta precisi√≥n
                - Resistente al sobreajuste
                - Maneja bien datos con muchas caracter√≠sticas
                """)
        rf_config = configure_random_forest(use_regression_model)
        models_config["Random Forest"] = rf_config
        current_config['rf_params'] = rf_config
    
    if "AdaBoost" in selected_models:
        st.subheader("AdaBoost")
        with st.expander("Explicaci√≥n de AdaBoost"):
            if use_regression_model:
                st.markdown("""
                **AdaBoost para Regresi√≥n** adapta el algoritmo boosting a problemas de regresi√≥n.
                
                **C√≥mo funciona:**
                1. Entrena secuencialmente m√∫ltiples regresores d√©biles
                2. Ajusta los pesos de las instancias, dando m√°s peso a las predicciones con mayor error
                3. Combina todos los regresores ponderando su contribuci√≥n
                
                **Ventajas:**
                - Buena precisi√≥n en regresi√≥n
                - Menos propenso al sobreajuste
                - Autom√°ticamente ajusta los pesos de las caracter√≠sticas
                """)
            else:
                st.markdown("""
                **AdaBoost** (Adaptive Boosting) es un algoritmo de boosting que combina m√∫ltiples clasificadores d√©biles.
                
                **C√≥mo funciona:**
                1. Entrena secuencialmente m√∫ltiples modelos d√©bils (generalmente √°rboles poco profundos)
                2. Ajusta los pesos de las instancias, dando m√°s peso a las mal clasificadas
                3. Combina todos los modelos d√©biles ponderando su contribuci√≥n
                
                **Ventajas:**
                - Alta precisi√≥n
                - Menos propenso al sobreajuste que otros algoritmos
                - Autom√°ticamente ajusta los pesos de las caracter√≠sticas
                """)
        ab_config = configure_adaboost(use_regression_model)
        models_config["AdaBoost"] = ab_config
        current_config['ab_params'] = ab_config
    
    if "Gradient Boosting" in selected_models:
        st.subheader("Gradient Boosting")
        with st.expander("Explicaci√≥n de Gradient Boosting"):
            if use_regression_model:
                st.markdown("""
                **Gradient Boosting para Regresi√≥n** optimiza funciones de p√©rdida para problemas de regresi√≥n.
                
                **C√≥mo funciona:**
                1. Construye modelos secuencialmente
                2. Cada nuevo modelo intenta corregir los errores residuales del modelo anterior
                3. Utiliza el descenso de gradiente para minimizar una funci√≥n de p√©rdida (MSE, MAE, etc.)
                
                **Ventajas:**
                - Muy alta precisi√≥n en regresi√≥n
                - Flexible con diferentes funciones de p√©rdida
                - Maneja bien datos heterog√©neos
                """)
            else:
                st.markdown("""
                **Gradient Boosting** es un algoritmo de boosting que optimiza una funci√≥n de p√©rdida mediante descenso de gradiente.
                
                **C√≥mo funciona:**
                1. Construye modelos secuencialmente
                2. Cada nuevo modelo intenta corregir los errores del modelo anterior
                3. Utiliza el descenso de gradiente para minimizar una funci√≥n de p√©rdida
                
                **Ventajas:**
                - Muy alta precisi√≥n
                - Flexible con diferentes funciones de p√©rdida
                - Maneja bien datos heterog√©neos
                """)
        gb_config = configure_gradient_boosting(use_regression_model)
        models_config["Gradient Boosting"] = gb_config
        current_config['gb_params'] = gb_config
    
    if "Bagging" in selected_models:
        st.subheader("Bagging")
        with st.expander("Explicaci√≥n de Bagging"):
            if use_regression_model:
                st.markdown("""
                **Bagging para Regresi√≥n** reduce la varianza en algoritmos de regresi√≥n.
                
                **C√≥mo funciona:**
                1. Crea m√∫ltiples subconjuntos de datos mediante muestreo con reemplazo (bootstrapping)
                2. Entrena un modelo de regresi√≥n en cada subconjunto
                3. Combina las predicciones de todos los modelos (promedio para regresi√≥n)
                
                **Ventajas:**
                - Reduce la varianza y ayuda a prevenir el sobreajuste
                - Funciona especialmente bien con algoritmos de alta varianza
                - Paralelizable (los modelos se entrenan independientemente)
                """)
            else:
                st.markdown("""
                **Bagging** (Bootstrap Aggregating) es una t√©cnica que reduce la varianza de los algoritmos de aprendizaje.
                
                **C√≥mo funciona:**
                1. Crea m√∫ltiples subconjuntos de datos mediante muestreo con reemplazo (bootstrapping)
                2. Entrena un modelo en cada subconjunto
                3. Combina las predicciones de todos los modelos (votaci√≥n para clasificaci√≥n)
                
                **Ventajas:**
                - Reduce la varianza y ayuda a prevenir el sobreajuste
                - Funciona especialmente bien con algoritmos de alta varianza como √°rboles de decisi√≥n
                - Paralelizable (los modelos se entrenan independientemente)
                """)
        bag_config = configure_bagging()
        models_config["Bagging"] = bag_config
        current_config['bag_params'] = bag_config
    
    # --- DETECCI√ìN DE CAMBIOS Y LIMPIEZA DE RESULTADOS ---
    config_changed = False
    if hasattr(st.session_state, 'ensemble_previous_state'):
        # Comparar configuraci√≥n actual con anterior
        for key in current_config:
            if current_config[key] != st.session_state.ensemble_previous_state.get(key):
                config_changed = True
                break
    
    # Si la configuraci√≥n cambi√≥, limpiar resultados anteriores
    if config_changed:
        st.session_state.ensemble_results = None
        st.session_state.ensemble_trained_models = None
        st.info("üîÑ Configuraci√≥n modificada. Entrena los modelos nuevamente.")
    
    # Guardar estado actual para la pr√≥xima comparaci√≥n
    st.session_state.ensemble_previous_state = current_config.copy()
    
    # --- ENTRENAMIENTO DEL MODELO ---
    train_button = st.button("Entrenar y Comparar Modelos", type="primary", key="train_ensemble_models")
    
    if train_button:
        results = train_models(models_config, X_train, y_train, X_test, y_test, random_state, use_regression_model)
        if results:
            st.session_state.ensemble_results = results
            st.session_state.ensemble_y_test = y_test
            st.session_state.use_regression_model = use_regression_model
            st.session_state.ensemble_trained_models = {name: result["model"] for name, result in results.items()}
            st.session_state.ensemble_X_columns = X.columns.tolist()
            st.session_state.ensemble_target_col = target_col
            st.session_state.ensemble_selected_features = selected_features
            st.session_state.ensemble_categorical_cols = categorical_cols if 'categorical_cols' in locals() else []
            st.session_state.ensemble_original_df = df
            st.success("‚úÖ Modelos entrenados exitosamente")
        else:
            st.error("‚ùå No se pudo entrenar ning√∫n modelo. Revisa par√°metros y datos.")
    
    # --- COMPARACI√ìN DE MODELOS (PRIMERO) ---
    if ('ensemble_results' in st.session_state and 
        st.session_state.ensemble_results is not None):
        st.subheader("Comparaci√≥n de Modelos")
        display_comparison_results(
            st.session_state.ensemble_results, 
            st.session_state.ensemble_y_test,
            st.session_state.use_regression_model
        )
    
    # --- PREDICCI√ìN CON MODELOS ENTRENADOS (DESPU√âS) ---
    if ('ensemble_trained_models' in st.session_state and 
        st.session_state.ensemble_trained_models is not None):
        
        st.subheader("Predicci√≥n con Modelos Entrenados")
        
        # Verificar si la configuraci√≥n sigue siendo compatible
        if config_changed:
            st.warning("‚ö†Ô∏è La configuraci√≥n ha cambiado. Los resultados de predicci√≥n pueden no ser v√°lidos.")
        
        prediction_method = st.radio(
            "Selecciona el m√©todo de predicci√≥n:",
            ["Ingresar datos manualmente", "Cargar archivo CSV"],
            key="prediction_method_ensemble"
        )
        
        if prediction_method == "Ingresar datos manualmente":
            st.write("**Ingresa los valores para las variables predictoras:**")
            
            # Crear inputs para cada feature - usar las columnas ORIGINALES
            input_data = {}
            col1, col2 = st.columns(2)
            
            for i, feature in enumerate(st.session_state.ensemble_selected_features):
                with col1 if i % 2 == 0 else col2:
                    # Verificar si la feature existe en el DataFrame original
                    if feature in st.session_state.ensemble_original_df.columns:
                        if st.session_state.ensemble_original_df[feature].dtype in ['object', 'category']:
                            # Variable categ√≥rica
                            unique_vals = st.session_state.ensemble_original_df[feature].dropna().unique()
                            input_val = st.selectbox(
                                f"{feature}:",
                                options=unique_vals,
                                key=f"input_{feature}_ensemble"
                            )
                        else:
                            # Variable num√©rica
                            min_val = float(st.session_state.ensemble_original_df[feature].min())
                            max_val = float(st.session_state.ensemble_original_df[feature].max())
                            mean_val = float(st.session_state.ensemble_original_df[feature].mean())
                            
                            input_val = st.number_input(
                                f"{feature} (rango: {min_val:.2f} - {max_val:.2f}):",
                                min_value=min_val,
                                max_value=max_val,
                                value=mean_val,
                                key=f"input_{feature}_ensemble"
                            )
                        input_data[feature] = input_val
                    else:
                        st.warning(f"‚ö†Ô∏è Columna '{feature}' no encontrada en datos originales")
            
            # Bot√≥n para predecir
            if st.button("Realizar Predicci√≥n", type="primary", key="manual_predict_ensemble"):
                try:
                    # Convertir input a DataFrame con las columnas originales
                    input_df = pd.DataFrame([input_data])
                    
                    # Aplicar el mismo preprocesamiento que a los datos de entrenamiento
                    processed_input = preprocess_new_data(
                        input_df, 
                        st.session_state.ensemble_selected_features,
                        st.session_state.ensemble_categorical_cols,
                        st.session_state.ensemble_X_columns
                    )
                    
                    # Realizar predicciones con todos los modelos
                    predictions = {}
                    for model_name, model in st.session_state.ensemble_trained_models.items():
                        if st.session_state.use_regression_model:
                            prediction = model.predict(processed_input)
                            predictions[model_name] = prediction[0]
                        else:
                            prediction = model.predict(processed_input)
                            prediction_proba = model.predict_proba(processed_input) if hasattr(model, "predict_proba") else None
                            predictions[model_name] = {
                                'class': prediction[0],
                                'probabilities': prediction_proba[0] if prediction_proba is not None else None,
                                'classes': model.classes_ if hasattr(model, 'classes_') else None
                            }
                    
                    # Mostrar resultados
                    st.subheader("Resultados de Predicci√≥n")
                    
                    if st.session_state.use_regression_model:
                        # Para regresi√≥n
                        results_df = pd.DataFrame({
                            'Modelo': list(predictions.keys()),
                            'Predicci√≥n': list(predictions.values())
                        })
                        st.dataframe(results_df)
                        
                        # Gr√°fico de comparaci√≥n
                        fig, ax = plt.subplots(figsize=(10, 6))
                        models = list(predictions.keys())
                        pred_values = list(predictions.values())
                        
                        bars = ax.bar(models, pred_values, color='skyblue', alpha=0.7, edgecolor='black')
                        ax.set_ylabel(f'Predicci√≥n de {st.session_state.ensemble_target_col}')
                        ax.set_title('Comparaci√≥n de Predicciones entre Modelos')
                        ax.tick_params(axis='x', rotation=45)
                        
                        # A√±adir valores en las barras
                        for bar, v in zip(bars, pred_values):
                            height = bar.get_height()
                            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                    f'{v:.4f}', ha='center', va='bottom', fontweight='bold')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                    else:
                        # Para clasificaci√≥n
                        results_data = []
                        for model_name, pred_info in predictions.items():
                            results_data.append({
                                'Modelo': model_name,
                                'Clase Predicha': pred_info['class'],
                                'Probabilidad M√°xima': (max(pred_info['probabilities']) 
                                                       if pred_info['probabilities'] is not None else 'N/A')
                            })
                        
                        results_df = pd.DataFrame(results_data)
                        st.dataframe(results_df)
                        
                        # Mostrar probabilidades detalladas si est√°n disponibles
                        st.write("**Probabilidades por Clase:**")
                        for model_name, pred_info in predictions.items():
                            if pred_info['probabilities'] is not None and pred_info['classes'] is not None:
                                with st.expander(f"Probabilidades - {model_name}"):
                                    prob_df = pd.DataFrame({
                                        'Clase': pred_info['classes'],
                                        'Probabilidad': pred_info['probabilities']
                                    }).sort_values('Probabilidad', ascending=False)
                                    
                                    st.dataframe(prob_df)
                                    
                                    # Gr√°fico de probabilidades
                                    fig, ax = plt.subplots(figsize=(10, 6))
                                    bars = ax.bar(prob_df['Clase'].astype(str), prob_df['Probabilidad'], 
                                                color='lightcoral', alpha=0.7, edgecolor='black')
                                    ax.set_ylabel('Probabilidad')
                                    ax.set_title(f'Probabilidades de Predicci√≥n - {model_name}')
                                    ax.set_ylim(0, 1)
                                    ax.tick_params(axis='x', rotation=45)
                                    
                                    # A√±adir valores en las barras
                                    for bar, v in zip(bars, prob_df['Probabilidad']):
                                        height = bar.get_height()
                                        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                                f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
                                    
                                    plt.tight_layout()
                                    st.pyplot(fig)
                        
                except Exception as e:
                    st.error(f"‚ùå Error en la predicci√≥n: {str(e)}")
        
        else:  # Cargar archivo CSV
            # Informaci√≥n para el usuario
            with st.expander("‚ÑπÔ∏è Instrucciones para archivo CSV"):
                st.markdown("""
                **‚ö†Ô∏è Formato requerido para archivo CSV de predicci√≥n:**
                
                - **Columnas requeridas:** Mismas variables predictoras ORIGINALES usadas en el entrenamiento
                - **Variables predictoras:** {}
                - **Formato de datos:** 
                    - Num√©ricos: Valores decimales o enteros
                    - Categ√≥ricos: Texto (debe coincidir con categor√≠as del entrenamiento)
                - **Codificaci√≥n:** UTF-8
                - **Separador:** Coma (,)
                - **No incluir:** variable objetivo '{}'
                - **Incluir:** Los nombres de columnas que deben ser id√©nticos a los originales
                """.format(', '.join(st.session_state.ensemble_selected_features), st.session_state.ensemble_target_col))
            
            st.write("**Carga un archivo CSV con datos para predecir:**")
            
            uploaded_file = st.file_uploader("Selecciona archivo CSV", type=['csv'], 
                                        key="prediction_file_ensemble")
            
            if uploaded_file is not None:
                try:
                    # Cargar datos
                    prediction_df = pd.read_csv(uploaded_file)
                    
                    st.write("**Vista previa de los datos cargados:**")
                    st.dataframe(prediction_df.head(), use_container_width=True)
                    
                    # Verificar columnas requeridas - usar las columnas ORIGINALES
                    required_columns = set(st.session_state.ensemble_selected_features)
                    missing_columns = required_columns - set(prediction_df.columns)
                    
                    if missing_columns:
                        st.error(f"‚ùå Faltan las siguientes columnas en el archivo: {', '.join(missing_columns)}")
                        st.info("**Columnas requeridas:**")
                        st.write(f"- **Variables predictoras:** {', '.join(st.session_state.ensemble_selected_features)}")
                        st.write(f"- **Formato esperado:** Mismas columnas originales usadas para entrenar el modelo")
                    else:
                        st.success("‚úÖ Todas las columnas requeridas est√°n presentes")
                        
                        # Procesar datos
                        X_pred = prediction_df[st.session_state.ensemble_selected_features]
                        X_pred_processed = preprocess_new_data(
                            X_pred, 
                            st.session_state.ensemble_selected_features,
                            st.session_state.ensemble_categorical_cols,
                            st.session_state.ensemble_X_columns
                        )
                        
                        # Realizar predicciones por lote
                        if st.button("Realizar Predicciones por Lote", type="primary", key="batch_predict_ensemble"):
                            try:
                                with st.spinner("Realizando predicciones..."):
                                    all_predictions = {}
                                    
                                    for model_name, model in st.session_state.ensemble_trained_models.items():
                                        if st.session_state.use_regression_model:
                                            predictions = model.predict(X_pred_processed)
                                            all_predictions[model_name] = predictions
                                        else:
                                            predictions = model.predict(X_pred_processed)
                                            all_predictions[model_name] = predictions
                                    
                                    # Crear DataFrame de resultados
                                    results_df = prediction_df.copy()
                                    for model_name, predictions in all_predictions.items():
                                        results_df[f'PREDICCION_{model_name}'] = predictions
                                    
                                    st.success(f"‚úÖ Predicciones completadas para {len(predictions)} registros")
                                    
                                    # Mostrar resultados
                                    st.write("**Resultados de Predicci√≥n:**")
                                    st.dataframe(results_df, use_container_width=True)
                                    
                                    # Descargar resultados
                                    csv = results_df.to_csv(index=False)
                                    st.download_button(
                                        label="üì• Descargar Resultados como CSV",
                                        data=csv,
                                        file_name=f"predicciones_ensemble_{st.session_state.ensemble_target_col}.csv",
                                        mime="text/csv",
                                        key="download_results_ensemble"
                                    )
                                    
                            except Exception as e:
                                st.error(f"‚ùå Error en predicciones por lote: {str(e)}")
                                
                except Exception as e:
                    st.error(f"‚ùå Error al cargar el archivo: {str(e)}")

def preprocess_new_data(new_data, selected_features, categorical_cols, X_columns):
    """Preprocesa nuevos datos de la misma manera que los datos de entrenamiento"""
    # Aplicar mismo preprocesamiento
    # 1. One-hot encoding para variables categ√≥ricas si existen
    if categorical_cols:
        try:
            new_data_cat = pd.get_dummies(new_data[categorical_cols], drop_first=True, dummy_na=False)
            new_data_non_cat = new_data[[col for col in new_data.columns if col not in categorical_cols]]
            new_data_processed = pd.concat([new_data_non_cat, new_data_cat], axis=1)
            
            # Asegurar que tenga las mismas columnas que X (el modelo entrenado)
            missing_cols = set(X_columns) - set(new_data_processed.columns)
            for col in missing_cols:
                new_data_processed[col] = 0
            
            # Reordenar columnas para que coincidan con X
            new_data_processed = new_data_processed[X_columns]
                
        except Exception as e:
            st.error(f"‚ùå Error en preprocesamiento: {str(e)}")
            # Si falla, intentar con las columnas originales
            new_data_processed = new_data[X_columns]
    else:
        new_data_processed = new_data[X_columns]
    
    return new_data_processed

def configure_random_forest(use_regression_model=False):
    col1, col2 = st.columns(2)
    with col1:
        n_estimators = st.slider("N√∫mero de √°rboles:", 10, 200, 100, key="rf_n_estimators")
        max_depth = st.slider("Profundidad m√°xima:", 1, 20, None, key="rf_max_depth")
    with col2:
        min_samples_split = st.slider("M√≠nimo samples para split:", 2, 20, 2, key="rf_min_samples")
        
        # CRITERIOS DIFERENTES PARA REGRESI√ìN VS CLASIFICACI√ìN
        if use_regression_model:
            criterion = st.selectbox("Criterio:", ["squared_error", "absolute_error", "friedman_mse"], 
                                   key="rf_criterion_reg")
        else:
            criterion = st.selectbox("Criterio:", ["gini", "entropy"], key="rf_criterion_clf")
    
    return {"n_estimators": n_estimators, "max_depth": max_depth,
            "min_samples_split": min_samples_split, "criterion": criterion}

def configure_adaboost(use_regression_model=False):
    col1, col2 = st.columns(2)
    with col1:
        n_estimators = st.slider("N√∫mero de estimadores:", 10, 200, 50, key="ab_n_estimators")
    with col2:
        learning_rate = st.slider("Learning rate:", 0.01, 1.0, 0.1, 0.01, key="ab_learning_rate")
    
    # PAR√ÅMETROS ESPEC√çFICOS PARA REGRESI√ìN
    if use_regression_model:
        col3, col4 = st.columns(2)
        with col3:
            loss = st.selectbox("Funci√≥n de p√©rdida:", ["linear", "square", "exponential"], 
                              key="ab_loss_reg")
        return {"n_estimators": n_estimators, "learning_rate": learning_rate, "loss": loss}
    else:
        return {"n_estimators": n_estimators, "learning_rate": learning_rate}

def configure_gradient_boosting(use_regression_model=False):
    col1, col2 = st.columns(2)
    with col1:
        n_estimators = st.slider("N√∫mero de estimadores:", 10, 200, 100, key="gb_n_estimators")
        learning_rate = st.slider("Learning rate:", 0.01, 0.3, 0.1, 0.01, key="gb_learning_rate")
    with col2:
        max_depth = st.slider("Profundidad m√°xima:", 1, 10, 3, key="gb_max_depth")
        min_samples_split = st.slider("M√≠nimo samples split:", 2, 20, 2, key="gb_min_samples")
    
    # CRITERIOS DIFERENTES PARA REGRESI√ìN
    if use_regression_model:
        criterion = st.selectbox("Criterio:", ["friedman_mse", "squared_error"], 
                               key="gb_criterion_reg")
        loss = st.selectbox("Funci√≥n de p√©rdida:", ["squared_error", "absolute_error", "huber", "quantile"], 
                          key="gb_loss_reg")
        return {"n_estimators": n_estimators, "learning_rate": learning_rate,
                "max_depth": max_depth, "min_samples_split": min_samples_split,
                "criterion": criterion, "loss": loss}
    else:
        return {"n_estimators": n_estimators, "learning_rate": learning_rate,
                "max_depth": max_depth, "min_samples_split": min_samples_split}

def configure_bagging():
    col1, col2 = st.columns(2)
    with col1:
        n_estimators = st.slider("N√∫mero de estimadores:", 10, 100, 10, key="bag_n_estimators")
    with col2:
        max_samples = st.slider("M√°ximo samples:", 0.1, 1.0, 1.0, 0.1, key="bag_max_samples")
    return {"n_estimators": n_estimators, "max_samples": max_samples}

def train_models(models_config, X_train, y_train, X_test, y_test, random_state, use_regression_model=False):
    results = {}
    for model_name, config in models_config.items():
        with st.spinner(f"Entrenando {model_name}..."):
            try:
                # Seleccionar el modelo adecuado seg√∫n el tipo de variable objetivo
                if use_regression_model:
                    # Modelos de regresi√≥n para variables num√©ricas
                    if model_name == "Random Forest":
                        # Validar criterio para regresi√≥n
                        if config.get("criterion") in ["gini", "entropy"]:
                            config["criterion"] = "squared_error"  # Valor por defecto para regresi√≥n
                        model = RandomForestRegressor(**config, random_state=random_state)
                    elif model_name == "AdaBoost":
                        model = AdaBoostRegressor(**config, random_state=random_state)
                    elif model_name == "Gradient Boosting":
                        model = GradientBoostingRegressor(**config, random_state=random_state)
                    elif model_name == "Bagging":
                        model = BaggingRegressor(**config, random_state=random_state)
                else:
                    # Modelos de clasificaci√≥n para variables categ√≥ricas
                    if model_name == "Random Forest":
                        model = RandomForestClassifier(**config, random_state=random_state)
                    elif model_name == "AdaBoost":
                        model = AdaBoostClassifier(**config, random_state=random_state)
                    elif model_name == "Gradient Boosting":
                        model = GradientBoostingClassifier(**config, random_state=random_state)
                    elif model_name == "Bagging":
                        model = BaggingClassifier(**config, random_state=random_state)

                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # Solo los modelos de clasificaci√≥n tienen predict_proba y classes_
                if use_regression_model:
                    results[model_name] = {
                        "y_pred": y_pred,
                        "model": model
                    }
                else:
                    y_prob = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None
                    results[model_name] = {
                        "y_pred": y_pred,
                        "y_prob": y_prob,
                        "classes": model.classes_,
                        "model": model
                    }
                    
                st.success(f"‚úÖ {model_name} entrenado exitosamente")

            except Exception as e:
                st.error(f"‚ùå Error al entrenar {model_name}: {str(e)}")
                # Debug information
                st.error(f"Configuraci√≥n usada: {config}")
    
    return results

def display_comparison_results(results, y_test, use_regression_model):    
    comparison_data = []
    
    if use_regression_model:
        # M√©tricas para modelos de regresi√≥n
        for model_name, result in results.items():
            y_pred = result["y_pred"]
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            comparison_data.append({
                "Modelo": model_name,
                "MSE": mse,
                "RMSE": rmse,
                "MAE": mae,
                "R¬≤": r2
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # Definir expl√≠citamente las columnas num√©ricas para el resaltado
        numeric_columns = ['MSE', 'RMSE', 'MAE', 'R¬≤']
        
        # Para MSE, RMSE y MAE, los valores m√°s bajos son mejores
        min_better = ['MSE', 'RMSE', 'MAE']
        # Para R¬≤, los valores m√°s altos son mejores
        max_better = ['R¬≤']
        
        # Aplicar formato y resaltado
        styled_df = comparison_df.style.format({
            'MSE': '{:.3f}', 
            'RMSE': '{:.3f}', 
            'MAE': '{:.3f}',
            'R¬≤': '{:.3f}'
        })
        
        # Resaltar los mejores valores (m√≠nimos para errores, m√°ximos para R¬≤)
        for col in min_better:
            styled_df = styled_df.highlight_min(
                subset=[col], 
                color='lightgreen',
                axis=0
            )
        
        for col in max_better:
            styled_df = styled_df.highlight_max(
                subset=[col], 
                color='lightgreen',
                axis=0
            )
    else:
        # M√©tricas para modelos de clasificaci√≥n
        for model_name, result in results.items():
            report = classification_report(y_test, result["y_pred"], output_dict=True)
            accuracy = report['accuracy']
            weighted_avg = report.get('weighted avg', {})
            comparison_data.append({
                "Modelo": model_name,
                "Accuracy": accuracy,
                "Recall": weighted_avg['recall'],
                "F1-Score": weighted_avg['f1-score']
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        
        # Definir expl√≠citamente las columnas num√©ricas para el resaltado
        numeric_columns = ['Accuracy', 'Recall', 'F1-Score']
        
        # Aplicar formato y resaltado SOLO a las columnas num√©ricas
        styled_df = comparison_df.style.format({
            'Accuracy': '{:.3f}', 
            'Recall': '{:.3f}', 
            'F1-Score': '{:.3f}'
        }).highlight_max(
            subset=numeric_columns, 
            color='lightgreen',
            axis=0  # Buscar m√°ximo por columna
        ).highlight_min(
            subset=numeric_columns, 
            color='#ffcccb',
            axis=0  # Buscar m√≠nimo por columna
        )
    
    st.dataframe(styled_df, use_container_width=True)

    # Resultados individuales
    for model_name, result in results.items():
        with st.expander(f"Resultados detallados - {model_name}"):
            if use_regression_model:
                show_regression_results(
                    y_test, 
                    result["y_pred"], 
                    model_name
                )
            else:
                show_model_results(
                    y_test, 
                    result["y_pred"], 
                    result["y_prob"], 
                    result["classes"], 
                    model_name, 
                    use_regression_model
                )

def show_regression_results(y_test, y_pred, model_name):
    """Muestra resultados para modelos de regresi√≥n"""
    tab1, tab2 = st.tabs(["M√©tricas de Error", "Visualizaciones"])
    
    with tab1:
        # Calcular m√©tricas
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # Mostrar m√©tricas en formato de tabla
        metrics_df = pd.DataFrame({
            'M√©trica': ['MSE', 'RMSE', 'MAE', 'R¬≤'],
            'Valor': [mse, rmse, mae, r2]
        })
        
        st.table(metrics_df.style.format({'Valor': '{:.4f}'}))
    
    with tab2:
        # Crear figura con dos subplots
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Gr√°fico de dispersi√≥n: Valores reales vs predicciones
        ax1.scatter(y_test, y_pred, alpha=0.5)
        ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        ax1.set_xlabel('Valores Reales')
        ax1.set_ylabel('Predicciones')
        ax1.set_title(f'{model_name}: Predicciones vs Valores Reales')
        
        # Histograma de residuos
        residuos = y_test - y_pred
        ax2.hist(residuos, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax2.axvline(x=0, color='red', linestyle='--')
        ax2.set_xlabel('Residuos')
        ax2.set_ylabel('Frecuencia')
        ax2.set_title('Distribuci√≥n de Residuos')
        
        plt.tight_layout()
        st.pyplot(fig)
        
        # Explicaci√≥n de los gr√°ficos
        with st.expander("Interpretaci√≥n de los gr√°ficos"):
            st.markdown("""
            **Predicciones vs Valores Reales**:
            - Los puntos deben estar cerca de la l√≠nea roja diagonal para un buen modelo.
            - Puntos dispersos indican mayor error en las predicciones.
            
            **Distribuci√≥n de Residuos**:
            - Idealmente debe ser sim√©trica alrededor de cero (l√≠nea roja).
            - Una distribuci√≥n sesgada puede indicar que el modelo tiene un sesgo sistem√°tico.
            - Valores extremos pueden indicar outliers o casos donde el modelo tiene dificultades.
            """)

def show_model_results(y_test, y_pred, y_prob, classes, model_name, use_regression_model):
    # Para variables categ√≥ricas, mostrar todas las pesta√±as
    tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Reporte de Clasificaci√≥n", "Curva ROC y AUC"])

    with tab1:
        show_confusion_matrix(y_test, y_pred, classes, model_name)
    
    with tab2:
        show_classification_report(y_test, y_pred, model_name)
    
    with tab3:
        show_roc_curve(y_test, y_prob, classes, model_name)

def show_confusion_matrix(y_test, y_pred, classes, model_name):
    """Muestra matriz de confusi√≥n con tama√±o de fuente ajustado"""
    cm = confusion_matrix(y_test, y_pred)
    
    # Ajustar tama√±o de figura seg√∫n n√∫mero de clases
    n_classes = len(classes)
    fig_size = max(8, n_classes * 0.8)
    
    fig, ax = plt.subplots(figsize=(fig_size, fig_size))
    
    # Tama√±o de fuente ajustable
    font_size = max(8, 12 - n_classes//2)
    
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=classes, yticklabels=classes, ax=ax,
                annot_kws={'size': font_size, 'weight': 'bold'},
                cbar_kws={'shrink': 0.8})
    
    ax.set_title(f"Matriz de Confusi√≥n - {model_name}", fontsize=12)
    ax.set_xlabel('Predicciones', fontsize=10)
    ax.set_ylabel('Valores Reales', fontsize=10)
    ax.tick_params(axis='both', which='major', labelsize=9)
    
    # Rotar etiquetas si hay muchas clases
    if n_classes > 5:
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
    
    st.pyplot(fig)

def show_classification_report(y_test, y_pred, model_name):
    report = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    accuracy = report['accuracy']
    weighted_avg = report.get('weighted avg', {})

    st.write("**M√©tricas Principales:**")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Exactitud", f"{accuracy:.3f}")
    col2.metric("Precisi√≥n", f"{weighted_avg.get('precision', 0):.3f}")
    col3.metric("Recall", f"{weighted_avg.get('recall', 0):.3f}")
    col4.metric("F1-Score", f"{weighted_avg.get('f1-score', 0):.3f}")

    st.write("**M√©tricas por Clase:**")
    st.dataframe(report_df.style.format({
        'precision': '{:.3f}', 'recall': '{:.3f}',
        'f1-score': '{:.3f}', 'support': '{:.0f}'
    }), use_container_width=True)

def show_roc_curve(y_test, y_prob, classes, model_name):
    if y_prob is not None and len(classes) > 1:
        try:
            n_classes = len(classes)
            fig, ax = plt.subplots(figsize=(10, 6))

            if n_classes == 2:
                fpr, tpr, _ = roc_curve(y_test, y_prob[:, 1])
                roc_auc = auc(fpr, tpr)
                ax.plot(fpr, tpr, lw=2, label=f"AUC = {roc_auc:.3f}")
            else:
                y_test_bin = label_binarize(y_test, classes=classes)
                colors = sns.color_palette("husl", n_classes)
                for i, color in zip(range(n_classes), colors):
                    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
                    roc_auc = auc(fpr, tpr)
                    ax.plot(fpr, tpr, color=color, lw=2,
                            label=f'Clase {classes[i]} (AUC = {roc_auc:.3f})')

            ax.plot([0, 1], [0, 1], 'k--', label='L√≠nea base')
            ax.set_xlabel("Tasa de Falsos Positivos")
            ax.set_ylabel("Tasa de Verdaderos Positivos")
            ax.set_title(f"Curva ROC - {model_name}")
            ax.legend(loc="lower right")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è No se pudo generar la curva ROC: {str(e)}")
    else:
        st.info("‚ÑπÔ∏è La curva ROC no est√° disponible para este modelo")