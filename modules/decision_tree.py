import streamlit as st 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import label_binarize
from sklearn.preprocessing import LabelEncoder
import graphviz
from io import StringIO
import pydotplus
from itertools import cycle

def decision_tree_module(df):
    st.subheader("Configuraci√≥n del √Årbol de Decisi√≥n")
    
    # --- INICIALIZACI√ìN DE ESTADO ---
    if 'dt_current_state' not in st.session_state:
        st.session_state.dt_current_state = {}
    
    # --- DETECCI√ìN DE CAMBIOS ---
    current_config = {
        'target_col': None,
        'selected_features': None,
        'cleaning_strategy': None,
        'numeric_option': None,
        'discretize_method': None,
        'n_bins': None,
        'test_size': None,
        'random_state': None,
        'criterion': None,
        'max_depth': None,
        'min_samples_split': None,
        'min_samples_leaf': None
    }
    
    # --- Preparaci√≥n de datos ---
    st.write("**Preparaci√≥n de datos:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Selecci√≥n de variable objetivo
        target_col = st.selectbox(
            "Selecciona la variable objetivo:",
            df.columns,
            key="target_select_dt"
        )
        current_config['target_col'] = target_col
    
    with col2:
        # Selecci√≥n de variables predictoras
        available_features = [col for col in df.columns if col != target_col]
        selected_features = st.multiselect(
            "Selecciona las variables predictoras:",
            available_features,
            default=available_features,
            key="features_select_dt"
        )
        current_config['selected_features'] = tuple(selected_features)  # Convertir a tuple para hash
    
    if not selected_features:
        st.warning("‚ö†Ô∏è Selecciona al menos una variable predictora")
        return
    
    # Construir X, y
    X = df[selected_features]
    y = df[target_col]
    
    # --- Limpieza y procesamiento de datos MEJORADO ---
    st.write("**Limpieza y procesamiento de datos:**")

    rows_before = len(X)

    # Verificar si hay valores infinitos o nulos
    has_inf = np.any(np.isinf(X.select_dtypes(include=['float64', 'int64']).values), axis=1).any()
    has_nulls_X = X.isnull().any().any()
    has_nulls_y = y.isnull().any()

    # Solo mostrar opciones de limpieza si hay valores problem√°ticos
    if has_inf or has_nulls_X or has_nulls_y:
        cleaning_strategy = st.selectbox(
            "Estrategia para manejar valores faltantes/infinitos:",
            ["Eliminar filas afectadas", "Rellenar con valores apropiados"],
            help="Eliminar: M√°s conservador | Rellenar: Preserva m√°s datos",
            key="cleaning_strategy_dt"
        )
        current_config['cleaning_strategy'] = cleaning_strategy
    else:
        cleaning_strategy = "Eliminar filas afectadas"
        st.info("‚ÑπÔ∏è No se detectaron valores infinitos ni nulos en el dataset")

    # 1. Manejar valores infinitos - solo si existen
    inf_mask = np.any(np.isinf(X.select_dtypes(include=['float64', 'int64']).values), axis=1)
    if inf_mask.any():
        st.warning(f"‚ö†Ô∏è Se detectaron {inf_mask.sum()} filas con valores infinitos.")
        
        if cleaning_strategy == "Eliminar filas afectadas":
            X = X[~inf_mask]
            y = y[~inf_mask]
            st.success("‚úÖ Filas con infinitos ELIMINADAS")
        else:
            # Reemplazar infinitos por NaN para luego imputar
            X = X.replace([np.inf, -np.inf], np.nan)
            st.info("‚ÑπÔ∏è Infinitos convertidos a NaN para imputaci√≥n")

    # 2. Manejar valores nulos - solo si existen
    total_missing_X = X.isnull().any(axis=1).sum()
    total_missing_y = y.isnull().sum()

    # Solo mostrar resumen si hay nulos
    if total_missing_X > 0 or total_missing_y > 0:
        st.write(f"**Resumen de valores nulos:**")
        if total_missing_X > 0:
            st.write(f"- Filas con nulos en predictores (X): {total_missing_X}")
        if total_missing_y > 0:
            st.write(f"- Filas con nulos en objetivo (y): {total_missing_y}")

    # Estrategia diferente para X vs y - solo aplicar si hay nulos
    if has_nulls_X or has_nulls_y:
        if cleaning_strategy == "Eliminar filas afectadas":
            # ELIMINAR: M√°s seguro para el modelo
            missing_mask = X.isnull().any(axis=1) | y.isnull()
            if missing_mask.any():
                rows_removed = missing_mask.sum()
                X = X[~missing_mask]
                y = y[~missing_mask]
                st.success(f"‚úÖ Se eliminaron {rows_removed} filas con valores nulos")
                
        else:
            # RELLENAR: Preserva datos
            # Para X: Imputar por tipo de variable
            numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            
            # Rellenar num√©ricos con mediana (m√°s robusta que media)
            for col in numeric_cols:
                if X[col].isna().any():
                    X[col] = X[col].fillna(X[col].median())
                    st.info(f"‚ÑπÔ∏è Num√©rico '{col}': nulos rellenados con mediana ({X[col].median():.2f})")
            
            # Rellenar categ√≥ricos con moda
            for col in categorical_cols:
                if X[col].isna().any():
                    mode_val = X[col].mode()[0] if not X[col].mode().empty else "DESCONOCIDO"
                    X[col] = X[col].fillna(mode_val)
                    st.info(f"‚ÑπÔ∏è Categ√≥rico '{col}': nulos rellenados con moda ('{mode_val}')")
            
            # Para y: Solo eliminar (cr√≠tico para el objetivo)
            if y.isnull().any():
                y_null_count = y.isnull().sum()
                mask = ~y.isnull()
                X = X[mask]
                y = y[mask]
                st.success(f"‚úÖ Se eliminaron {y_null_count} filas con nulos en variable objetivo (CR√çTICO)")

    # 3. Verificaci√≥n final - solo mostrar si hubo cambios
    rows_after = len(X)
    rows_removed_total = rows_before - rows_after

    if rows_removed_total > 0:
        removal_percentage = (rows_removed_total / rows_before) * 100
        st.warning(f"‚ö†Ô∏è Resumen final: {rows_removed_total} filas removidas ({removal_percentage:.1f}%)")
        
        if removal_percentage > 30:
            st.error("‚ùå ¬°Alto porcentaje de datos perdidos! Considera revisar tu dataset")
        elif removal_percentage > 10:
            st.warning("‚ö†Ô∏è Porcentaje moderado de datos perdidos")
    else:
        st.info("‚ÑπÔ∏è No se removieron filas durante la limpieza")

    st.info(f"‚ÑπÔ∏è Filas restantes para modelo: {rows_after}")

    if len(X) < 10:
        st.error("‚ùå Dataset demasiado peque√±o despu√©s de limpieza. No se puede continuar.")
        return
    elif len(X) < 50:
        st.warning("‚ö†Ô∏è Dataset muy peque√±o. Los resultados pueden no ser confiables.")
        
    # Detectar variables categ√≥ricas (solo expl√≠citas - objetos y categor√≠as)
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

    if categorical_cols:
        st.info(f"‚ÑπÔ∏è Variables categ√≥ricas detectadas: {', '.join(categorical_cols)}")
        
        # Convertir a dummies con manejo de errores m√°s robusto
        try:
            # Crear una copia de seguridad de X
            X_backup = X.copy()
            
            # Convertir solo las columnas categ√≥ricas
            X_cat = pd.get_dummies(X[categorical_cols], drop_first=True, dummy_na=False)
            
            # Mantener las columnas num√©ricas que no son categ√≥ricas
            non_cat_cols = [col for col in X.columns if col not in categorical_cols]
            X_non_cat = X[non_cat_cols]
            
            # Combinar ambos conjuntos de datos
            X = pd.concat([X_non_cat, X_cat], axis=1)
            
            st.success(f"‚úÖ Variables categ√≥ricas convertidas a one-hot encoding. Nuevas dimensiones: {X.shape}")
        except Exception as e:
            st.error(f"‚ùå Error al convertir variables categ√≥ricas: {str(e)}")
            st.warning("Intentando m√©todo alternativo de conversi√≥n...")
            
            try:
                # Restaurar X desde la copia de seguridad
                X = X_backup.copy()
                
                # M√©todo alternativo: convertir una por una
                for col in categorical_cols:
                    try:
                        # Convertir a string primero para manejar diferentes tipos de datos
                        X[col] = X[col].astype(str)
                    except Exception as e_col:
                        st.warning(f"No se pudo convertir la columna '{col}': {str(e_col)}")
                
                # Intentar la conversi√≥n con manejo expl√≠cito de columnas
                dummies_list = []
                remaining_cols = []
                
                for col in X.columns:
                    if col in categorical_cols:
                        try:
                            # Crear dummies para esta columna
                            dummies = pd.get_dummies(X[col], prefix=col, drop_first=True)
                            dummies_list.append(dummies)
                        except Exception as e_dummy:
                            st.warning(f"Error al crear dummies para '{col}': {str(e_dummy)}")
                            # Mantener la columna original si falla
                            remaining_cols.append(col)
                    else:
                        remaining_cols.append(col)
                
                # Reconstruir el DataFrame
                if dummies_list:
                    all_dummies = pd.concat(dummies_list, axis=1)
                    X = pd.concat([X[remaining_cols], all_dummies], axis=1)
                    st.success(f"‚úÖ Variables convertidas con m√©todo alternativo. Nuevas dimensiones: {X.shape}")
                else:
                    st.warning("‚ö†Ô∏è No se pudieron crear variables dummy. Manteniendo variables originales.")
            except Exception as e2:
                st.error(f"‚ùå Error en m√©todo alternativo: {str(e2)}")
                st.warning("‚ö†Ô∏è Continuando con las variables originales sin convertir a dummies.")
    else:
        st.info("‚ÑπÔ∏è No se detectaron variables categ√≥ricas en los predictores")
        st.info("‚úÖ **One-hot encoding:** No requerido - no hay variables categ√≥ricas")
    
    # Procesamiento de variable objetivo
    # Detectar si la variable objetivo es num√©rica o categ√≥rica
    is_numeric_target = pd.api.types.is_numeric_dtype(y)
    
    # Variable para controlar si usamos regresi√≥n o clasificaci√≥n
    use_regression_model = True  # Valor por defecto
    
    if is_numeric_target:
        st.info(f"‚ÑπÔ∏è Variable objetivo '{target_col}' detectada como num√©rica/continua")
        
        # Para variables num√©ricas, verificamos valores nulos y outliers
        if y.isna().any():
            st.warning(f"‚ö†Ô∏è Se eliminaron {y.isna().sum()} filas con valores nulos en la variable objetivo")
            mask = ~y.isna()
            X = X[mask]
            y = y[mask]
        
        # Detectar y manejar outliers (opcional)
        Q1 = y.quantile(0.25)
        Q3 = y.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = (y < lower_bound) | (y > upper_bound)
        
        if outliers.sum() > 0:
            st.info(f"‚ÑπÔ∏è Se detectaron {outliers.sum()} valores at√≠picos en la variable objetivo")
        
        # Opciones para manejar variables num√©ricas
        st.subheader("Opciones para variable objetivo num√©rica")
        numeric_option = st.radio(
            "¬øC√≥mo deseas manejar la variable objetivo num√©rica?",
            ["Discretizar en intervalos para clasificaci√≥n", "Usar modelo de regresi√≥n"],
            key="numeric_option_dt"
        )
        current_config['numeric_option'] = numeric_option
        
        if numeric_option == "Discretizar en intervalos para clasificaci√≥n":
            use_regression_model = False
            # Opciones de discretizaci√≥n
            discretize_method = st.selectbox(
                "M√©todo de discretizaci√≥n:",
                ["Intervalos iguales", "Cuantiles", "Personalizado"],
                key="discretize_method_dt"
            )
            current_config['discretize_method'] = discretize_method
            
            if discretize_method == "Intervalos iguales":
                n_bins = st.slider("N√∫mero de intervalos:", 2, 10, 4, key="n_bins_equal_dt")
                current_config['n_bins'] = n_bins
                # Discretizar en intervalos iguales
                bins = np.linspace(y.min(), y.max(), n_bins + 1)
                labels = [f'{bins[i]:.2f}-{bins[i+1]:.2f}' for i in range(len(bins)-1)]
                y_discretized = pd.cut(y, bins=bins, labels=labels, include_lowest=True)
                
                # Mostrar distribuci√≥n de clases
                class_counts = y_discretized.value_counts().sort_index()
                st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                st.bar_chart(class_counts)
                
                # Reemplazar la variable objetivo con la versi√≥n discretizada
                y = y_discretized
                st.success(f"‚úÖ Variable objetivo discretizada en {n_bins} intervalos iguales")
                is_numeric_target = False
                
            elif discretize_method == "Cuantiles":
                n_bins = st.slider("N√∫mero de cuantiles:", 2, 10, 4, key="n_bins_quantile_dt")
                current_config['n_bins'] = n_bins
                # Discretizar por cuantiles
                bins = pd.qcut(y, q=n_bins, retbins=True)[1]
                labels = [f'{bins[i]:.2f}-{bins[i+1]:.2f}' for i in range(len(bins)-1)]
                y_discretized = pd.cut(y, bins=bins, labels=labels, include_lowest=True)
                
                # Mostrar distribuci√≥n de clases
                class_counts = y_discretized.value_counts().sort_index()
                st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                st.bar_chart(class_counts)
                
                # Reemplazar la variable objetivo con la versi√≥n discretizada
                y = y_discretized
                st.success(f"‚úÖ Variable objetivo discretizada en {n_bins} cuantiles")
                is_numeric_target = False
                
            elif discretize_method == "Personalizado":
                use_regression_model = False
                # Permitir al usuario definir puntos de corte personalizados
                min_val = float(y.min())
                max_val = float(y.max())
                
                st.write(f"Rango de valores: {min_val:.2f} a {max_val:.2f}")
                
                # Entrada de texto para puntos de corte
                cutpoints_text = st.text_input(
                    "Puntos de corte (separados por coma):",
                    value=f"{min_val},{(min_val+max_val)/2:.2f},{max_val}",
                    key="custom_cutpoints_dt"
                )
                
                try:
                    # Convertir texto a lista de puntos de corte
                    cutpoints = [float(x.strip()) for x in cutpoints_text.split(",")]
                    cutpoints = sorted(list(set(cutpoints)))  # Eliminar duplicados y ordenar
                    
                    if len(cutpoints) < 2:
                        st.error("‚ùå Se necesitan al menos 2 puntos de corte")
                    else:
                        # Asegurarse de que los puntos de corte cubran todo el rango
                        if cutpoints[0] > min_val:
                            cutpoints.insert(0, min_val)
                        if cutpoints[-1] < max_val:
                            cutpoints.append(max_val)
                        
                        # Crear etiquetas y discretizar
                        labels = [f'{cutpoints[i]:.2f}-{cutpoints[i+1]:.2f}' for i in range(len(cutpoints)-1)]
                        y_discretized = pd.cut(y, bins=cutpoints, labels=labels, include_lowest=True)
                        
                        # Mostrar distribuci√≥n de clases
                        class_counts = y_discretized.value_counts().sort_index()
                        st.write("Distribuci√≥n de clases despu√©s de discretizaci√≥n:")
                        st.bar_chart(class_counts)
                        
                        # Reemplazar la variable objetivo con la versi√≥n discretizada
                        y = y_discretized
                        st.success(f"‚úÖ Variable objetivo discretizada con puntos de corte personalizados")
                        is_numeric_target = False
                        
                except Exception as e:
                    st.error(f"‚ùå Error al procesar puntos de corte: {str(e)}")
        else:
            # Para √°rboles de decisi√≥n con variable objetivo num√©rica, usamos DecisionTreeRegressor
            use_regression_model = True
            st.info("‚ÑπÔ∏è Se utilizar√° un modelo de regresi√≥n (DecisionTreeRegressor) para la variable objetivo num√©rica")
        
    else:
        st.info(f"‚ÑπÔ∏è Variable objetivo '{target_col}' detectada como categ√≥rica")
        use_regression_model = False
        
        # Para variables categ√≥ricas, limpiamos y procesamos
        y = y.astype(str).str.strip()
        y = y.replace("?", np.nan)
        mask = ~y.isna()
        X = X[mask]
        y = y[mask]

        # Eliminaci√≥n de clases raras
        class_counts = y.value_counts()
        rare_classes = class_counts[class_counts < 2].index
        if len(rare_classes) > 0:
            st.warning(f"‚ö†Ô∏è Se eliminaron {len(rare_classes)} clases con menos de 2 muestras")
            mask = ~y.isin(rare_classes)
            X = X[mask]
            y = y[mask]
        
        # Validaci√≥n final para clasificaci√≥n
        if len(y.unique()) < 2:
            st.error("‚ùåNo hay suficientes clases para entrenar el modelo. Se necesitan al menos 2 clases diferentes.")
            return
    
    # --- Configuraci√≥n de divisi√≥n de datos ---
    st.write("**Configuraci√≥n de divisi√≥n de datos:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        test_size = st.slider("Tama√±o del conjunto de prueba:", 0.1, 0.4, 0.2, 0.05,
                            key="test_size_dt")
        current_config['test_size'] = test_size
    
    with col2:
        random_state = st.number_input("Random state:", 0, 100, 42, key="random_state_dt")
        current_config['random_state'] = random_state
    
    # Validar estratificaci√≥n
    can_stratify = len(y.unique()) >= 2 and y.value_counts().min() >= 2
    
    # Divisi√≥n del dataset
    try:
        if can_stratify and not use_regression_model:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=test_size,
                random_state=random_state,
                stratify=y,
                shuffle=True
            )
            st.success("‚úÖ Divisi√≥n estratificada realizada correctamente")
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y,
                test_size=test_size,
                random_state=random_state,
                shuffle=True
            )
            st.info("‚ÑπÔ∏è Divisi√≥n no estratificada realizada")
    except ValueError as e:
        st.warning(f"‚ö†Ô∏è Divisi√≥n estratificada fall√≥: {e}. Reintentando sin estratificaci√≥n...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=test_size,
            random_state=random_state,
            shuffle=True
        )
    
    # --- Configuraci√≥n de hiperpar√°metros seg√∫n selecci√≥n ---
    st.subheader("Configuraci√≥n de Hiperpar√°metros")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if use_regression_model:
            # Hiperpar√°metros para regresi√≥n
            criterion = st.selectbox(
                "Criterio de divisi√≥n:",
                ["squared_error", "friedman_mse", "absolute_error", "poisson"],
                help="Criterios espec√≠ficos para modelos de regresi√≥n",
                key="criterion_reg_dt"
            )
        else:
            # Hiperpar√°metros para clasificaci√≥n
            criterion = st.selectbox(
                "Criterio de divisi√≥n:",
                ["gini", "entropy"],
                help="GINI: medida de impureza | Entropy: ganancia de informaci√≥n",
                key="criterion_clf_dt"
            )
        current_config['criterion'] = criterion
        
        max_depth = st.slider("Profundidad m√°xima:", 1, 20, 5, key="max_depth_dt")
        current_config['max_depth'] = max_depth
    
    with col2:
        min_samples_split = st.slider("M√≠nimo samples para split:", 2, 20, 2, 
                                    key="min_samples_split_dt")
        current_config['min_samples_split'] = min_samples_split
        
        min_samples_leaf = st.slider("M√≠nimo samples por hoja:", 1, 10, 1, 
                                   key="min_samples_leaf_dt")
        current_config['min_samples_leaf'] = min_samples_leaf
    
    # --- DETECCI√ìN DE CAMBIOS Y LIMPIEZA DE RESULTADOS ---
    config_changed = False
    if hasattr(st.session_state, 'dt_previous_state'):
        # Comparar configuraci√≥n actual con anterior
        for key in current_config:
            if current_config[key] != st.session_state.dt_previous_state.get(key):
                config_changed = True
                break
    
    # Si la configuraci√≥n cambi√≥, limpiar resultados anteriores
    if config_changed:
        st.session_state.model_trained = False
        st.session_state.trained_model = None
        st.info("üîÑ Configuraci√≥n modificada. Entrena el modelo nuevamente.")
    
    # Guardar estado actual para la pr√≥xima comparaci√≥n
    st.session_state.dt_previous_state = current_config.copy()
    
    # --- ENTRENAMIENTO DEL MODELO ---
    train_button = st.button("Entrenar √Årbol de Decisi√≥n", type="primary", key="train_model_dt")
    
    if train_button:
        try:
            with st.spinner("Entrenando modelo..."):
                # Usar regressor o classifier seg√∫n el tipo de variable objetivo
                if use_regression_model:
                    # Para regresi√≥n
                    model = DecisionTreeRegressor(
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        random_state=random_state
                    )
                    model.fit(X_train, y_train)
                    
                    y_pred = model.predict(X_test)
                    y_prob = None  # No hay probabilidades en regresi√≥n
                    
                    st.success("‚úÖ Modelo de regresi√≥n entrenado exitosamente")
                    display_regression_results(y_test, y_pred)
                else:
                    # Para clasificaci√≥n, verificamos que haya suficientes clases
                    if len(np.unique(y_train)) < 2:
                        st.error("‚ùå El conjunto de entrenamiento debe tener al menos 2 clases diferentes")
                        return
                    
                    model = DecisionTreeClassifier(
                        criterion=criterion,
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        random_state=random_state
                    )
                    model.fit(X_train, y_train)
                    
                    y_pred = model.predict(X_test)
                    try:
                        y_prob = model.predict_proba(X_test)
                    except Exception:
                        y_prob = None
                    
                    st.success("‚úÖ Modelo de clasificaci√≥n entrenado exitosamente")
                    display_classification_results(y_test, y_pred, y_prob, model.classes_, use_regression_model)
                
                # Visualizaci√≥n del √°rbol
                st.subheader("Visualizaci√≥n del √Årbol de Decisi√≥n")
                
                # Crear visualizaci√≥n del √°rbol
                fig, ax = plt.subplots(figsize=(12, 8))
                
                # Determinar feature_names y class_names
                feature_names = X.columns.tolist()
                
                if use_regression_model:
                    class_names = None  # No hay nombres de clase para regresi√≥n
                else:
                    if hasattr(model, 'classes_'):
                        class_names = [str(c) for c in model.classes_]
                    else:
                        class_names = [str(c) for c in np.unique(y)]
                
                # Dibujar el √°rbol con configuraci√≥n predeterminada
                plot_tree(model, 
                        max_depth=3,  # Profundidad fija para mejor visualizaci√≥n
                        feature_names=feature_names,
                        class_names=class_names,
                        filled=True,
                        rounded=True,
                        ax=ax,
                        fontsize=10)
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # Guardar el modelo en session_state para usarlo en predicciones
                st.session_state.trained_model = model
                st.session_state.model_trained = True
                st.session_state.use_regression_model = use_regression_model
                st.session_state.target_col = target_col
                st.session_state.selected_features = selected_features
                st.session_state.X_columns = X.columns.tolist()
                st.session_state.categorical_cols = categorical_cols if 'categorical_cols' in locals() else []
                st.session_state.original_df = df
        
        except Exception as e:
            st.error(f"‚ùå Error al entrenar el modelo: {str(e)}")
            st.write("Sugerencia: Verifica la variable objetivo, ajusta los hiperpar√°metros o revisa las variables predictoras.")

    # --- PREDICCI√ìN CON EL MODELO ENTRENADO ---
    # Solo mostrar si el modelo ha sido entrenado
    if 'model_trained' in st.session_state and st.session_state.model_trained:
        st.subheader("Predicci√≥n con el Modelo Entrenado")
        
        # Verificar si la configuraci√≥n sigue siendo compatible
        if config_changed:
            st.warning("‚ö†Ô∏è La configuraci√≥n ha cambiado. Los resultados de predicci√≥n pueden no ser v√°lidos.")
        
        # Recuperar variables del session_state
        model = st.session_state.trained_model
        use_regression_model = st.session_state.use_regression_model
        target_col = st.session_state.target_col
        selected_features = st.session_state.selected_features
        X_columns = st.session_state.X_columns
        categorical_cols = st.session_state.categorical_cols
        original_df = st.session_state.original_df
        
        prediction_method = st.radio(
            "Selecciona el m√©todo de predicci√≥n:",
            ["Ingresar datos manualmente", "Cargar archivo CSV"],
            key="prediction_method_dt"
        )

        if prediction_method == "Ingresar datos manualmente":
            st.write("**Ingresa los valores para las variables predictoras:**")
            
            # Crear inputs para cada feature - usar las columnas ORIGINALES
            input_data = {}
            col1, col2 = st.columns(2)
            
            for i, feature in enumerate(selected_features):
                with col1 if i % 2 == 0 else col2:
                    # Verificar si la feature existe en el DataFrame original
                    if feature in original_df.columns:
                        if original_df[feature].dtype in ['object', 'category']:
                            # Variable categ√≥rica
                            unique_vals = original_df[feature].dropna().unique()
                            input_val = st.selectbox(
                                f"{feature}:",
                                options=unique_vals,
                                key=f"input_{feature}_dt"
                            )
                        else:
                            # Variable num√©rica
                            min_val = float(original_df[feature].min())
                            max_val = float(original_df[feature].max())
                            mean_val = float(original_df[feature].mean())
                            
                            input_val = st.number_input(
                                f"{feature} (rango: {min_val:.2f} - {max_val:.2f}):",
                                min_value=min_val,
                                max_value=max_val,
                                value=mean_val,
                                key=f"input_{feature}_dt"
                            )
                        input_data[feature] = input_val
                    else:
                        st.warning(f"‚ö†Ô∏è Columna '{feature}' no encontrada en datos originales")
            
            # Bot√≥n para predecir
            if st.button("Realizar Predicci√≥n", type="primary", key="manual_predict_dt"):
                try:
                    # Convertir input a DataFrame con las columnas originales
                    input_df = pd.DataFrame([input_data])
                    
                    # Aplicar el mismo preprocesamiento que a los datos de entrenamiento
                    # 1. One-hot encoding para variables categ√≥ricas si existen
                    if categorical_cols:
                        # Crear dummies para las columnas categ√≥ricas
                        input_cat = pd.get_dummies(input_df[categorical_cols], drop_first=True, dummy_na=False)
                        
                        # Mantener las columnas num√©ricas
                        input_non_cat = input_df[[col for col in input_df.columns if col not in categorical_cols]]
                        
                        # Combinar ambos conjuntos de datos
                        input_processed = pd.concat([input_non_cat, input_cat], axis=1)
                        
                        # Asegurar que tenga las mismas columnas que X (el modelo entrenado)
                        missing_cols = set(X_columns) - set(input_processed.columns)
                        for col in missing_cols:
                            input_processed[col] = 0
                        
                        # Reordenar columnas para que coincidan con X
                        input_processed = input_processed[X_columns]
                            
                    else:
                        # Si no hay variables categ√≥ricas, usar directamente
                        input_processed = input_df[X_columns]
                    
                    # Realizar predicci√≥n
                    if use_regression_model:
                        prediction = model.predict(input_processed)
                        st.success(f"**üìä Predicci√≥n:** {prediction[0]:.4f}")
                        
                        # Mostrar interpretaci√≥n para regresi√≥n
                        st.info(f"El modelo predice un valor de **{prediction[0]:.4f}** para la variable objetivo '{target_col}'")
                        
                    else:
                        prediction = model.predict(input_processed)
                        prediction_proba = model.predict_proba(input_processed)
                        
                        st.success(f"**üìä Predicci√≥n:** {prediction[0]}")
                        
                        # Mostrar probabilidades
                        st.write("**Probabilidades por clase:**")
                        prob_df = pd.DataFrame({
                            'Clase': model.classes_,
                            'Probabilidad': prediction_proba[0]
                        }).sort_values('Probabilidad', ascending=False)
                        
                        # Gr√°fico de probabilidades
                        fig, ax = plt.subplots(figsize=(10, 6))
                        bars = ax.bar(prob_df['Clase'].astype(str), prob_df['Probabilidad'], 
                                    color='skyblue', edgecolor='black', alpha=0.7)
                        ax.set_ylabel('Probabilidad')
                        ax.set_xlabel('Clases')
                        ax.set_title('Probabilidades de Predicci√≥n por Clase')
                        ax.set_ylim(0, 1)
                        
                        # A√±adir valores en las barras
                        for bar in bars:
                            height = bar.get_height()
                            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                f'{height:.3f}', ha='center', va='bottom', fontweight='bold')
                        
                        plt.xticks(rotation=45)
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                except Exception as e:
                    st.error(f"‚ùå Error en la predicci√≥n: {str(e)}")
                    st.info("‚ÑπÔ∏è Esto puede ocurrir si hay discrepancias en el preprocesamiento de datos")

        else:  
            # Informaci√≥n para el usuario
            with st.expander("‚ÑπÔ∏è Instrucciones para archivo CSV"):
                st.markdown("""
                **‚ö†Ô∏è Formato requerido para archivo CSV de predicci√≥n:**
                
                - **Columnas requeridas:** Mismas variables predictoras ORIGINALES usadas en el entrenamiento
                - **Variables predictoras:** {}
                - **Formato de datos:** 
                    - Num√©ricos: Valores decimales o enteros
                    - Categ√≥ricos: Texto (debe coincidir con categor√≠as del entrenamiento)
                - **Codificaci√≥n:** UTF-8
                - **Separador:** Coma (,)
                - **No incluir:** variable objetivo '{}'
                - **Incluir:** Los nombres de columnas que deben ser id√©nticos a los originales
                """.format(', '.join(selected_features), target_col))
                # Cargar archivo CSV
            st.write("**Carga un archivo CSV con datos para predecir:**")
            
            uploaded_file = st.file_uploader("Selecciona archivo CSV", type=['csv'], 
                                        key="prediction_file_dt")
            
            if uploaded_file is not None:
                try:
                    # Cargar datos
                    prediction_df = pd.read_csv(uploaded_file)
                    
                    st.write("**Vista previa de los datos cargados:**")
                    st.dataframe(prediction_df.head(), use_container_width=True)
                    
                    # Verificar columnas requeridas - usar las columnas ORIGINALES
                    required_columns = set(selected_features)
                    missing_columns = required_columns - set(prediction_df.columns)
                    
                    if missing_columns:
                        st.error(f"‚ùå Faltan las siguientes columnas en el archivo: {', '.join(missing_columns)}")
                        st.info("**Columnas requeridas:**")
                        st.write(f"- **Variables predictoras:** {', '.join(selected_features)}")
                        st.write(f"- **Formato esperado:** Mismas columnas originales usadas para entrenar el modelo")
                    else:
                        st.success("‚úÖ Todas las columnas requeridas est√°n presentes")
                        
                        # Procesar datos igual que en entrenamiento
                        X_pred = prediction_df[selected_features]
                        
                        # Aplicar mismo preprocesamiento
                        # 1. Manejar infinitos
                        inf_mask = np.any(np.isinf(X_pred.select_dtypes(include=['float64', 'int64']).values), axis=1)
                        if inf_mask.any():
                            st.warning(f"‚ö†Ô∏è Se detectaron {inf_mask.sum()} filas con valores infinitos. Ser√°n eliminadas.")
                            X_pred = X_pred[~inf_mask]
                        
                        # 2. One-hot encoding si hay variables categ√≥ricas
                        if categorical_cols:
                            try:
                                X_pred_cat = pd.get_dummies(X_pred[categorical_cols], drop_first=True, dummy_na=False)
                                X_pred_non_cat = X_pred[[col for col in X_pred.columns if col not in categorical_cols]]
                                X_pred_processed = pd.concat([X_pred_non_cat, X_pred_cat], axis=1)
                                
                                # Asegurar mismas columnas que el modelo
                                missing_cols = set(X_columns) - set(X_pred_processed.columns)
                                for col in missing_cols:
                                    X_pred_processed[col] = 0
                                
                                # Reordenar columnas
                                X_pred_processed = X_pred_processed[X_columns]
                                    
                            except Exception as e:
                                st.error(f"‚ùå Error en preprocesamiento: {str(e)}")
                                st.info("Intentando procesamiento alternativo...")
                                X_pred_processed = X_pred[X_columns]  # Usar columnas originales
                        else:
                            X_pred_processed = X_pred[X_columns]
                        
                        # Realizar predicciones
                        if st.button("Realizar Predicciones por Lote", type="primary", key="batch_predict_dt"):
                            try:
                                with st.spinner("Realizando predicciones..."):
                                    if use_regression_model:
                                        predictions = model.predict(X_pred_processed)
                                        results_df = prediction_df.copy()
                                        results_df[f'PREDICCION_{target_col}'] = predictions
                                        
                                        st.success(f"‚úÖ Predicciones completadas para {len(predictions)} registros")
                                        
                                        # Mostrar resultados
                                        st.write("**Resultados de Predicci√≥n:**")
                                        st.dataframe(results_df, use_container_width=True)                                   
                                        
                                    else:
                                        predictions = model.predict(X_pred_processed)
                                        predictions_proba = model.predict_proba(X_pred_processed)
                                        
                                        results_df = prediction_df.copy()
                                        results_df[f'PREDICCION_{target_col}'] = predictions
                                        results_df['PROBABILIDAD_MAXIMA'] = predictions_proba.max(axis=1)
                                        
                                        # A√±adir probabilidades por clase
                                        for i, class_name in enumerate(model.classes_):
                                            results_df[f'PROB_{class_name}'] = predictions_proba[:, i]
                                        
                                        st.success(f"‚úÖ Predicciones completadas para {len(predictions)} registros")
                                        
                                        # Mostrar resultados
                                        st.write("**Resultados de Predicci√≥n:**")
                                        st.dataframe(results_df, use_container_width=True)
                                        
                                        # Distribuci√≥n de predicciones
                                        st.write("**Distribuci√≥n de Predicciones:**")
                                        pred_counts = results_df[f'PREDICCION_{target_col}'].value_counts()
                                        
                                        # Gr√°fico de distribuci√≥n de clases predichas
                                        fig, ax = plt.subplots(figsize=(10, 6))

                                        # Gr√°fico de distribuci√≥n
                                        ax.bar(pred_counts.index.astype(str), pred_counts.values, 
                                            color='lightcoral', alpha=0.7, edgecolor='black')
                                        ax.set_xlabel('Clase Predicha')
                                        ax.set_ylabel('Cantidad')
                                        ax.set_title('Distribuci√≥n de Clases Predichas')
                                        ax.tick_params(axis='x', rotation=45)

                                        # A√±adir valores en las barras
                                        for i, v in enumerate(pred_counts.values):
                                            ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontweight='bold')
                                        
                                        plt.tight_layout()
                                        st.pyplot(fig)
                                
                                # Descargar resultados
                                csv = results_df.to_csv(index=False)
                                st.download_button(
                                    label="üì• Descargar Resultados como CSV",
                                    data=csv,
                                    file_name=f"predicciones_arbol_decision_{target_col}.csv",
                                    mime="text/csv",
                                    key="download_results_dt"
                                )
                                
                            except Exception as e:
                                st.error(f"‚ùå Error en predicciones por lote: {str(e)}")
                                
                except Exception as e:
                    st.error(f"‚ùå Error al cargar el archivo: {str(e)}")

# [Las funciones display_regression_results, display_classification_results, e interpretar_auc permanecen iguales]
def display_regression_results(y_test, y_pred):
    """Muestra los resultados para modelos de regresi√≥n"""
    st.subheader("Resultados de la Evaluaci√≥n (Regresi√≥n)")
    
    # Calcular m√©tricas de regresi√≥n
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # Mostrar m√©tricas en una tabla
    metrics_df = pd.DataFrame({
        'M√©trica': ['Error Cuadr√°tico Medio (MSE)', 'Ra√≠z del Error Cuadr√°tico Medio (RMSE)', 
                   'Error Absoluto Medio (MAE)', 'Coeficiente de Determinaci√≥n (R¬≤)'],
        'Valor': [mse, rmse, mae, r2]
    })
    
    st.write("**M√©tricas de Evaluaci√≥n:**")
    st.dataframe(metrics_df)
    
    # Visualizaci√≥n de predicciones vs valores reales
    st.write("**Predicciones vs Valores Reales:**")
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.scatter(y_test, y_pred, alpha=0.5)
    
    # A√±adir l√≠nea de referencia perfecta
    min_val = min(y_test.min(), y_pred.min())
    max_val = max(y_test.max(), y_pred.max())
    ax.plot([min_val, max_val], [min_val, max_val], 'r--')
    
    ax.set_xlabel('Valores Reales')
    ax.set_ylabel('Predicciones')
    ax.set_title('Comparaci√≥n de Predicciones vs Valores Reales')
    
    # A√±adir texto con m√©tricas
    ax.text(0.05, 0.95, f'R¬≤ = {r2:.4f}\nRMSE = {rmse:.4f}', 
            transform=ax.transAxes, fontsize=12,
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    st.pyplot(fig)
    
    # Histograma de residuos
    residuals = y_test - y_pred
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    ax.axvline(x=0, color='red', linestyle='--')
    ax.set_xlabel('Residuos')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Distribuci√≥n de Residuos')
    
    st.pyplot(fig)

def display_classification_results(y_test, y_pred, y_prob, classes, use_regression_model):
    """Muestra los resultados para modelos de clasificaci√≥n"""
    st.subheader("Resultados de la Evaluaci√≥n (Clasificaci√≥n)")
    
    # Determinar el tipo de problema
    n_classes = len(classes)
    is_binary_classification = n_classes == 2
    is_multiclass_classification = n_classes > 2
    
    # Mostrar curvas ROC solo para clasificaci√≥n (no regresi√≥n)
    if not use_regression_model and y_prob is not None:
        if is_binary_classification:
            tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Reporte de Clasificaci√≥n", "Curva ROC"])
        elif is_multiclass_classification:
            tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Reporte de Clasificaci√≥n", "Curvas ROC"])
        else:
            tab1, tab2 = st.tabs(["Matriz de Confusi√≥n", "Reporte de Clasificaci√≥n"])
    else:
        tab1, tab2 = st.tabs(["Matriz de Confusi√≥n", "Reporte de Clasificaci√≥n"])
    
    # Matriz de Confusi√≥n
    with tab1:
        st.write("**Matriz de Confusi√≥n:**")
        cm = confusion_matrix(y_test, y_pred)

        num_classes = len(classes)

        # Ajustes din√°micos para matriz de confusi√≥n
        if num_classes == 2:
            fig_width, fig_height = 6, 5
            font_size = 16
            tick_font_size = 14
            annotation_size = 18
        elif num_classes <= 5:
            fig_width, fig_height = 8, 7
            font_size = 14
            tick_font_size = 12
            annotation_size = 14
        elif num_classes <= 10:
            fig_width = min(1 + num_classes * 0.5, 12)
            fig_height = min(1 + num_classes * 0.5, 12)
            font_size = 10
            tick_font_size = 10
            annotation_size = 10
        else:
            fig_width = min(1 + num_classes * 0.5, 20)
            fig_height = min(1 + num_classes * 0.5, 20)
            font_size = 8
            tick_font_size = 8
            annotation_size = 8

        fig, ax = plt.subplots(figsize=(fig_width, fig_height))

        # Crear heatmap con mejoras visuales
        heatmap = sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=classes,
            yticklabels=classes,
            annot_kws={'size': annotation_size, 'weight': 'bold'},
            cbar_kws={'shrink': 0.7},
            square=True
        )

        # Mejorar etiquetas y t√≠tulo
        ax.set_xlabel('Predicciones', fontsize=tick_font_size + 2, weight='bold')
        ax.set_ylabel('Valores Reales', fontsize=tick_font_size + 2, weight='bold')
        ax.set_title('Matriz de Confusi√≥n', fontsize=font_size + 4, weight='bold', pad=20)

        # Rotar etiquetas horizontales para evitar traslape
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)

        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=tick_font_size)
        ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=tick_font_size)

        # A√±adir l√≠neas de separaci√≥n m√°s visibles para pocas clases
        if num_classes <= 5:
            for i in range(num_classes + 1):
                ax.axhline(i, color='white', linewidth=2)
                ax.axvline(i, color='white', linewidth=2)

        plt.tight_layout()
        st.pyplot(fig)

        # Mostrar advertencia si hay demasiadas clases
        if num_classes > 15:
            st.warning("‚ö†Ô∏è Hay muchas clases en la variable objetivo. Considera agrupar clases similares para una mejor visualizaci√≥n.")

        # Informaci√≥n adicional para matrices peque√±as
        if num_classes == 2:
            st.info("""
            **üìä Interpretaci√≥n para 2 clases:**
            - **Verdaderos Negativos (TN)**: Casos negativos correctamente clasificados
            - **Falsos Positivos (FP)**: Casos negativos incorrectamente clasificados como positivos
            - **Falsos Negativos (FN)**: Casos positivos incorrectamente clasificados como negativos  
            - **Verdaderos Positivos (TP)**: Casos positivos correctamente clasificados
            """)

    # Reporte de Clasificaci√≥n Simplificado
    with tab2:
        st.subheader("Reporte de Clasificaci√≥n")
        
        if y_test is not None and y_pred is not None:
            # Calcular el reporte
            report = classification_report(y_test, y_pred, output_dict=True)
            
            accuracy = report.get('accuracy', 0)
            macro_avg = report.get('macro avg', {})
            weighted_avg = report.get('weighted avg', {})
            
            # Obtener m√©tricas por clase
            class_metrics = {}
            for key in report.keys():
                if key not in ['accuracy', 'macro avg', 'weighted avg'] and isinstance(report[key], dict):
                    class_metrics[key] = report[key]
            
            # M√©tricas Globales
            st.write("**M√©tricas Globales del Modelo**")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    label="Exactitud (Accuracy)",
                    value=f"{accuracy:.3f}",
                    help="Porcentaje total de predicciones correctas"
                )
            
            with col2:
                precision_avg = weighted_avg.get('precision', macro_avg.get('precision', 0))
                st.metric(
                    label="Precisi√≥n Promedio",
                    value=f"{precision_avg:.3f}",
                    help="Capacidad del modelo para no predecir falsos positivos"
                )
            
            with col3:
                recall_avg = weighted_avg.get('recall', macro_avg.get('recall', 0))
                st.metric(
                    label="Recall Promedio", 
                    value=f"{recall_avg:.3f}",
                    help="Capacidad del modelo para encontrar todos los positivos"
                )
            
            with col4:
                f1_avg = weighted_avg.get('f1-score', macro_avg.get('f1-score', 0))
                st.metric(
                    label="F1-Score Promedio",
                    value=f"{f1_avg:.3f}",
                    help="Balance entre Precisi√≥n y Recall"
                )

            # Mostrar m√©tricas por clase si hay m√∫ltiples clases
            if class_metrics and len(class_metrics) > 1:
                class_metrics_df = pd.DataFrame(class_metrics).transpose()
                
                # Gr√°fico de rendimiento por clase
                st.write("**Rendimiento por Clase**")
                
                fig, ax = plt.subplots(figsize=(10, 5))
                
                classes = class_metrics_df.index
                x = np.arange(len(classes))
                width = 0.25
                
                # Crear barras para cada m√©trica
                bars1 = ax.bar(x - width, class_metrics_df['precision'], width, label='Precisi√≥n', alpha=0.8, color='#FF6B6B')
                bars2 = ax.bar(x, class_metrics_df['recall'], width, label='Recall', alpha=0.8, color='#4ECDC4')
                bars3 = ax.bar(x + width, class_metrics_df['f1-score'], width, label='F1-Score', alpha=0.8, color='#45B7D1')
                
                # Personalizar gr√°fico
                ax.set_xlabel('Clases')
                ax.set_ylabel('Puntuaci√≥n')
                ax.set_title('M√©tricas por Clase')
                ax.set_xticks(x)
                ax.set_xticklabels(classes, rotation=45, ha='right')
                ax.legend()
                ax.set_ylim(0, 1.05)
                ax.grid(True, alpha=0.3, axis='y')
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # Tabla de m√©tricas
                st.write("**Tabla de M√©tricas por Clase**")
                
                class_metrics_display = class_metrics_df.copy()
                class_metrics_display.index.name = 'Clase'
                class_metrics_display = class_metrics_display.reset_index()
                
                st.dataframe(
                    class_metrics_display.style.format({
                        'precision': '{:.3f}',
                        'recall': '{:.3f}', 
                        'f1-score': '{:.3f}',
                        'support': '{:.0f}'
                    }),
                    use_container_width=True,
                    height=min(300, 100 + len(class_metrics_df) * 35)
                )
            
            elif class_metrics and len(class_metrics) == 1:
                # Caso binario
                st.info("Clasificaci√≥n binaria")
                class_name = list(class_metrics.keys())[0]
                metrics = class_metrics[class_name]
                
                st.write(f"**M√©tricas para la clase {class_name}:**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Precisi√≥n", f"{metrics['precision']:.3f}")
                with col2:
                    st.metric("Recall", f"{metrics['recall']:.3f}")
                with col3:
                    st.metric("F1-Score", f"{metrics['f1-score']:.3f}")

        else:
            st.warning("No hay datos de prueba o predicciones disponibles")
            
    # Curvas ROC solo para clasificaci√≥n (no regresi√≥n) y con soporte multiclase
    if not use_regression_model and y_prob is not None:
        if is_binary_classification:
            with tab3:
                with st.expander("Curva ROC (Receiver Operating Characteristic)"):
                    st.markdown("""
                La **Curva ROC** es una representaci√≥n gr√°fica que muestra la capacidad de un clasificador 
                para diferenciar entre clases. Se basa en two m√©tricas:
                
                - **Tasa de falsos positivos (False Positive Rate - FPR):** Proporci√≥n de negativos incorrectamente clasificados como positivos.
                - **Tasa de verdaderos positivos (True Positive Rate - TPR):** Proporci√≥n de positivos correctamente identificados.
                
                La curva muestra la relaci√≥n entre TPR y FPR para diferentes umbrales de decisi√≥n.
                
                **Nota:** La curva ROC solo est√° disponible para problemas de clasificaci√≥n binaria.
                """)
                
                try:
                    # Convertir y_test a num√©rico
                    class_mapping = {class_name: i for i, class_name in enumerate(classes)}
                    y_test_numeric = np.array([class_mapping[label] for label in y_test])
                    
                    # Gr√°fico: CURVA ROC
                    st.subheader("Curva ROC")

                    fig_width = 10
                    fig_height = 8
                    fig_roc, ax_roc = plt.subplots(figsize=(fig_width, fig_height))

                    # Clasificaci√≥n binaria
                    pos_label = 1
                    
                    fpr, tpr, _ = roc_curve(y_test_numeric, y_prob[:, pos_label], pos_label=pos_label)
                    roc_auc = auc(fpr, tpr)
                    
                    ax_roc.plot(fpr, tpr, color='darkorange', lw=3, label=f'Curva ROC (AUC = {roc_auc:.3f})')
                    ax_roc.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='L√≠nea base (AUC = 0.5)')
                    ax_roc.set_xlim([0.0, 1.0])
                    ax_roc.set_ylim([0.0, 1.05])
                    ax_roc.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=11)
                    ax_roc.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=11)
                    ax_roc.set_title('Curva ROC - Clasificaci√≥n Binaria', fontsize=13, fontweight='bold')
                    
                    # Mostrar qu√© clase se considera positiva
                    positive_class = classes[pos_label]
                    negative_class = classes[0]
                    ax_roc.text(0.02, 0.98, f'Clase positiva: {positive_class}\nClase negativa: {negative_class}', 
                               transform=ax_roc.transAxes, fontsize=10, 
                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
                    
                    # Leyenda fuera del gr√°fico
                    ax_roc.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), fontsize=10)
                    ax_roc.grid(True, alpha=0.3)
                    
                    # Ajustar tama√±o de ticks
                    ax_roc.tick_params(axis='both', which='major', labelsize=10)

                    # Ajustar el layout para hacer espacio para la leyenda
                    plt.tight_layout(rect=[0, 0, 0.85, 1])
                    st.pyplot(fig_roc)
                    
                    with st.expander("√Årea bajo la curva (AUC)"):
                        st.markdown("""
                    El **AUC** cuantifica la calidad de la curva ROC en un solo valor:
                    
                    - **0.9 - 1.0:** Excelente poder discriminativo
                    - **0.8 - 0.9:** Muy bueno
                    - **0.7 - 0.8:** Aceptable
                    - **0.6 - 0.7:** Pobre
                    - **0.5 - 0.6:** No mejor que aleatorio
                    - **< 0.5:** Peor que aleatorio
                    """)
                            
                    # Mostrar m√©tricas num√©ricas
                    st.subheader("M√©tricas de Evaluaci√≥n AUC")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("AUC Score", f"{roc_auc:.4f}")
                    with col2:
                        st.metric("Interpretaci√≥n", interpretar_auc(roc_auc))
                    with col3:
                        quality = "‚úÖ Excelente" if roc_auc >= 0.9 else "üëç Buena" if roc_auc >= 0.8 else "‚ö†Ô∏è Aceptable" if roc_auc >= 0.7 else "‚ùå Pobre"
                        st.metric("Calidad", quality)
                    
                    # Gr√°fico de m√©tricas AUC
                    fig_auc, ax_auc = plt.subplots(figsize=(8, 6))
                    
                    metrics_data = [roc_auc]
                    metric_labels = ['AUC']
                    colors = ['lightgreen' if roc_auc >= 0.7 else 'lightcoral']
                    
                    bars = ax_auc.bar(metric_labels, metrics_data, color=colors, edgecolor='black', alpha=0.8)
                    ax_auc.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Aleatorio')
                    ax_auc.axhline(y=0.7, color='orange', linestyle='--', alpha=0.7, label='Aceptable')
                    ax_auc.axhline(y=0.9, color='green', linestyle='--', alpha=0.7, label='Excelente')
                    ax_auc.set_ylim(0, 1.1)
                    ax_auc.set_ylabel('Valor AUC')
                    ax_auc.set_title('M√©trica AUC - Clasificaci√≥n Binaria')
                    ax_auc.legend()
                    
                    # A√±adir valores en las barras
                    for bar, v in zip(bars, metrics_data):
                        height = bar.get_height()
                        ax_auc.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                f'{v:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=12)
                    
                    plt.tight_layout()
                    st.pyplot(fig_auc)
                            
                except Exception as e:
                    st.error(f"‚ùå Error al calcular las curvas ROC: {str(e)}")
                    st.info("‚ÑπÔ∏è Esto puede ocurrir cuando hay problemas con las probabilidades predichas o las clases objetivo")
        
        elif is_multiclass_classification:
            with tab3:
                st.subheader("Curvas ROC para Clasificaci√≥n Multiclase")
                
                try:
                    # Convertir y_test a formato num√©rico
                    le = LabelEncoder()
                    y_test_encoded = le.fit_transform(y_test)
                    
                    # Binarizar las etiquetas para multiclase
                    y_test_bin = label_binarize(y_test_encoded, classes=np.unique(y_test_encoded))
                    n_classes = y_test_bin.shape[1]
                    
                    # Calcular curvas ROC y AUC para cada clase
                    fpr = dict()
                    tpr = dict()
                    roc_auc = dict()
                    
                    for i in range(n_classes):
                        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])
                        roc_auc[i] = auc(fpr[i], tpr[i])
                    
                    # Calcular micro-average ROC curve y ROC area
                    fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_prob.ravel())
                    roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])
                    
                    # Calcular macro-average ROC curve y ROC area
                    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))
                    mean_tpr = np.zeros_like(all_fpr)
                    for i in range(n_classes):
                        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
                    mean_tpr /= n_classes
                    fpr["macro"] = all_fpr
                    tpr["macro"] = mean_tpr
                    roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])
                    
                    # Plot all ROC curves
                    fig, ax = plt.subplots(figsize=(10, 8))
                    
                    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 
                                  'brown', 'pink', 'gray', 'olive', 'cyan', 'magenta'])
                    
                    for i, color in zip(range(n_classes), colors):
                        ax.plot(fpr[i], tpr[i], color=color, lw=2,
                                label='ROC clase {0} (AUC = {1:0.2f})'
                                ''.format(classes[i], roc_auc[i]))
                    
                    # Plot micro and macro averages
                    ax.plot(fpr["micro"], tpr["micro"],
                            label='ROC micro-promedio (AUC = {0:0.2f})'
                            ''.format(roc_auc["micro"]),
                            color='deeppink', linestyle=':', linewidth=4)
                    
                    ax.plot(fpr["macro"], tpr["macro"],
                            label='ROC macro-promedio (AUC = {0:0.2f})'
                            ''.format(roc_auc["macro"]),
                            color='navy', linestyle=':', linewidth=4)
                    
                    # Plot diagonal line
                    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='L√≠nea base (AUC = 0.5)')
                    
                    ax.set_xlim([0.0, 1.0])
                    ax.set_ylim([0.0, 1.05])
                    ax.set_xlabel('Tasa de Falsos Positivos (FPR)')
                    ax.set_ylabel('Tasa de Verdaderos Positivos (TPR)')
                    ax.set_title('Curvas ROC - Clasificaci√≥n Multiclase')
                    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
                    ax.grid(True, alpha=0.3)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # Mostrar m√©tricas de AUC
                    st.subheader("M√©tricas AUC por Clase")
                    
                    auc_data = []
                    for i in range(n_classes):
                        auc_data.append({
                            'Clase': classes[i],
                            'AUC': roc_auc[i],
                            'Interpretaci√≥n': interpretar_auc(roc_auc[i])
                        })
                    
                    # A√±adir promedios
                    auc_data.append({
                        'Clase': 'Micro-promedio',
                        'AUC': roc_auc["micro"],
                        'Interpretaci√≥n': interpretar_auc(roc_auc["micro"])
                    })
                    auc_data.append({
                        'Clase': 'Macro-promedio', 
                        'AUC': roc_auc["macro"],
                        'Interpretaci√≥n': interpretar_auc(roc_auc["macro"])
                    })
                    
                    auc_df = pd.DataFrame(auc_data)
                    st.dataframe(auc_df.style.format({'AUC': '{:.4f}'}))
                    
                    # Gr√°fico de barras para AUC por clase
                    fig_auc, ax_auc = plt.subplots(figsize=(12, 6))
                    
                    classes_auc = [f'Clase {i}' for i in range(n_classes)] + ['Micro', 'Macro']
                    auc_values = [roc_auc[i] for i in range(n_classes)] + [roc_auc["micro"], roc_auc["macro"]]
                    colors_auc = ['lightblue' if x >= 0.7 else 'lightcoral' for x in auc_values]
                    
                    bars = ax_auc.bar(classes_auc, auc_values, color=colors_auc, edgecolor='black', alpha=0.8)
                    ax_auc.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Aleatorio')
                    ax_auc.axhline(y=0.7, color='orange', linestyle='--', alpha=0.7, label='Aceptable')
                    ax_auc.set_ylim(0, 1.1)
                    ax_auc.set_ylabel('Valor AUC')
                    ax_auc.set_title('M√©tricas AUC por Clase - Clasificaci√≥n Multiclase')
                    ax_auc.legend()
                    ax_auc.tick_params(axis='x', rotation=45)
                    
                    # A√±adir valores en las barras
                    for bar, v in zip(bars, auc_values):
                        height = bar.get_height()
                        ax_auc.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                                f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
                    
                    plt.tight_layout()
                    st.pyplot(fig_auc)
                    
                except Exception as e:
                    st.error(f"‚ùå Error al calcular curvas ROC multiclase: {str(e)}")
                    st.info("‚ÑπÔ∏è Esto puede ocurrir cuando hay problemas con las probabilidades predichas o las clases objetivo")

def interpretar_auc(auc_score):
    """Funci√≥n auxiliar para interpretar scores AUC"""
    if auc_score >= 0.9:
        return "Excelente discriminaci√≥n"
    elif auc_score >= 0.8:
        return "Muy buena discriminaci√≥n"
    elif auc_score >= 0.7:
        return "Discriminaci√≥n aceptable"
    elif auc_score >= 0.6:
        return "Discriminaci√≥n pobre"
    elif auc_score >= 0.5:
        return "No mejor que aleatorio"
    else:
        return "Peor que aleatorio"